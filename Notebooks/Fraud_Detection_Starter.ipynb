{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKfpS4UVJ4Wj"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-17T05:26:10.850691Z",
     "iopub.status.busy": "2023-12-17T05:26:10.849991Z",
     "iopub.status.idle": "2023-12-17T05:26:10.864708Z",
     "shell.execute_reply": "2023-12-17T05:26:10.864106Z",
     "shell.execute_reply.started": "2023-12-17T05:26:10.850638Z"
    },
    "id": "OJMD_I3EJWP4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import feature_column\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "e6LfbE6PJbmp",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "id": "IYR_e0SMJnpa",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  2.84 Mb (54.2% reduction)\n",
      "Mem. usage decreased to 315.93 Mb (42.2% reduction)\n",
      "Mem. usage decreased to  1.11 Mb (50.0% reduction)\n",
      "Mem. usage decreased to 122.09 Mb (48.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "curdir = os.getcwd()\n",
    "DATA_DIR = f'{curdir}/Data'\n",
    "TRAIN_DIR = f'{DATA_DIR}/train'\n",
    "TEST_DIR = f'{DATA_DIR}/test'\n",
    "OUTPUT_DIR = f'{DATA_DIR}/output'\n",
    "\n",
    "for pth in [TRAIN_DIR, TEST_DIR, OUTPUT_DIR]:\n",
    "    if not os.path.exists(pth):\n",
    "        os.makedirs(pth)\n",
    "train_zip = \"train.zip\"\n",
    "test_zip = \"test.zip\"\n",
    "sample_sub = \"SampleSubmission.csv\"\n",
    "with zipfile.ZipFile(f'{TRAIN_DIR}/train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(TRAIN_DIR)\n",
    "with zipfile.ZipFile(f'{TEST_DIR}/test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(TEST_DIR)\n",
    "client_train = reduce_mem_usage(pd.read_csv(f'{TRAIN_DIR}/client_train.csv', low_memory=False))\n",
    "invoice_train = reduce_mem_usage(pd.read_csv(f'{TRAIN_DIR}/invoice_train.csv', low_memory=False))\n",
    "\n",
    "client_test = reduce_mem_usage(pd.read_csv(f'{TEST_DIR}/client_test.csv', low_memory=False))\n",
    "invoice_test = reduce_mem_usage(pd.read_csv(f'{TEST_DIR}/invoice_test.csv', low_memory=False))\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/SampleSubmission.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "Jy_tdygDJm-k",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Data Cleaning: get rid of useless/inconsistent data that are not useful in training phase.\n",
    "Remove clients with bad counter_statue and remarque in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "invoice_train = invoice_train.drop(invoice_train[invoice_train.tarif_type == \"18\"].index)\n",
    "invoice_train = invoice_train.query(\"counter_statue in ['0','1','2','3','4','5']\")\n",
    "bad_statue_client = ['train_Client_78338','train_Client_13203','train_Client_53725','train_Client_47780','train_Client_30467']\n",
    "invoice_train = invoice_train[~invoice_train[\"client_id\"].isin(bad_statue_client)]\n",
    "invoice_train = invoice_train[~((invoice_train[\"client_id\"]=='train_Client_79075') & (invoice_train['counter_type']=='GAZ'))].reset_index(drop=True)\n",
    "\n",
    "client_train = client_train[~client_train[\"client_id\"].isin(bad_statue_client)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_clients(client, Train = False):\n",
    "    client['client_catg'] = client['client_catg'].astype(\"string\")\n",
    "    client['region_group'] =  client['region'].astype(\"int64\").apply(lambda x: 1 if x<=100 else 3 if x>=300 else 2)\n",
    "    client['region'] = client['region'].astype(\"string\")\n",
    "    client['disrict'] = client['disrict'].astype(\"string\")\n",
    "    client[\"creation_date\"] = pd.to_datetime(client['creation_date'],dayfirst=True)\n",
    "    client['creation_day'] = client['creation_date'].dt.day\n",
    "    client['creation_month'] = client['creation_date'].dt.month\n",
    "    client['creation_year'] = client['creation_date'].dt.year\n",
    "    client['duration']=(2022 - client['creation_date'].dt.year)*12 - client['creation_date'].dt.month\n",
    "    client['CreationYear'] = client['creation_date'].dt.strftime('%Y').astype(float)\n",
    "    client = reduce_mem_usage(client)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  6.59 Mb (31.1% reduction)\n",
      "Mem. usage decreased to  2.71 Mb (31.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "client_train = clean_clients(client_train)\n",
    "client_test = clean_clients(client_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse_output=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False,categories='auto')\n",
    "\n",
    "ohe_columns = []\n",
    "ohe_cat_cols = ['disrict','client_catg','region']\n",
    "\n",
    "ohe.fit(client_train[ohe_cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 11.76 Mb (67.8% reduction)\n",
      "Mem. usage decreased to  4.93 Mb (68.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "for i,c in enumerate(ohe_cat_cols):\n",
    "    ohe_columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
    "dummy_train = pd.DataFrame(ohe.transform(client_train[ohe_cat_cols]),columns=ohe_columns)\n",
    "client_train = reduce_mem_usage(pd.concat([client_train.drop(ohe_cat_cols,axis=1),dummy_train],axis=1))\n",
    "dummy_test = pd.DataFrame(ohe.transform(client_test[ohe_cat_cols]),columns=ohe_columns)\n",
    "client_test = reduce_mem_usage(pd.concat([client_test.drop(ohe_cat_cols,axis=1),dummy_test],axis=1))\n",
    "del dummy_train\n",
    "del dummy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 446.69 Mb (1.4% reduction)\n",
      "Mem. usage decreased to 428.34 Mb (4.1% reduction)\n",
      "Mem. usage decreased to 416.10 Mb (20.9% reduction)\n",
      "Mem. usage decreased to 611.91 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 1052.48 Mb (11.3% reduction)\n",
      "Mem. usage decreased to  5.91 Mb (0.0% reduction)\n",
      "Mem. usage decreased to  8.86 Mb (25.0% reduction)\n",
      "Mem. usage decreased to 12.92 Mb (12.5% reduction)\n",
      "Mem. usage decreased to 16.98 Mb (9.8% reduction)\n",
      "Mem. usage decreased to 19.94 Mb (12.9% reduction)\n",
      "Mem. usage decreased to 22.89 Mb (7.5% reduction)\n",
      "Mem. usage decreased to 25.47 Mb (8.0% reduction)\n",
      "Mem. usage decreased to 29.90 Mb (4.7% reduction)\n",
      "Mem. usage decreased to 32.49 Mb (9.3% reduction)\n",
      "Mem. usage decreased to 37.66 Mb (12.1% reduction)\n",
      "Mem. usage decreased to 42.82 Mb (10.8% reduction)\n",
      "Mem. usage decreased to 47.99 Mb (9.7% reduction)\n",
      "Mem. usage decreased to 53.16 Mb (8.9% reduction)\n",
      "Mem. usage decreased to 58.33 Mb (8.1% reduction)\n",
      "Mem. usage decreased to 63.50 Mb (7.5% reduction)\n",
      "Mem. usage decreased to 68.67 Mb (7.0% reduction)\n",
      "Mem. usage decreased to 73.84 Mb (6.5% reduction)\n",
      "Mem. usage decreased to 79.00 Mb (6.1% reduction)\n",
      "Mem. usage decreased to 84.17 Mb (5.8% reduction)\n",
      "Mem. usage decreased to 89.34 Mb (0.8% reduction)\n",
      "Mem. usage decreased to 94.51 Mb (0.8% reduction)\n",
      "Mem. usage decreased to 97.09 Mb (2.2% reduction)\n",
      "Mem. usage decreased to 99.68 Mb (2.2% reduction)\n",
      "Mem. usage decreased to 102.63 Mb (2.8% reduction)\n",
      "Mem. usage decreased to 107.06 Mb (1.4% reduction)\n",
      "Mem. usage decreased to 111.86 Mb (1.0% reduction)\n",
      "Mem. usage decreased to 114.45 Mb (2.8% reduction)\n",
      "Mem. usage decreased to 117.03 Mb (1.9% reduction)\n",
      "Mem. usage decreased to 119.61 Mb (1.8% reduction)\n",
      "Mem. usage decreased to 124.04 Mb (1.2% reduction)\n",
      "Mem. usage decreased to 126.63 Mb (2.6% reduction)\n",
      "Mem. usage decreased to 131.80 Mb (0.6% reduction)\n",
      "Mem. usage decreased to 136.60 Mb (0.8% reduction)\n",
      "Mem. usage decreased to 137.34 Mb (1.6% reduction)\n",
      "Mem. usage decreased to 138.07 Mb (1.6% reduction)\n",
      "Mem. usage decreased to 139.18 Mb (1.3% reduction)\n",
      "Mem. usage decreased to 140.29 Mb (1.3% reduction)\n",
      "Mem. usage decreased to 141.03 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 141.77 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 142.50 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 143.24 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 143.98 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 144.72 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 145.46 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 146.20 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 146.93 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 147.67 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 148.41 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 149.15 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 149.89 Mb (1.5% reduction)\n",
      "Mem. usage decreased to 184.22 Mb (32.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([invoice_train,invoice_test],axis=0).reset_index(drop=True)\n",
    "data = reduce_mem_usage(data)\n",
    "# Adjust Wrong Column Vlues\n",
    "idx = data['months_number']>100\n",
    "data.loc[idx,['old_index','new_index']] = data.loc[idx,['new_index','months_number']].values\n",
    "data.loc[idx,['months_number']] = 4\n",
    "data.loc[data['months_number']==0,['months_number']] = 4\n",
    "data = reduce_mem_usage(data)\n",
    "# Adjust Consumption\n",
    "data['consommation_level_1'] = round(data['consommation_level_1']/data['months_number'],0)\n",
    "data['consommation_level_2'] = round(data['consommation_level_2']/data['months_number'],0)\n",
    "data['consommation_level_3'] = round(data['consommation_level_3']/data['months_number'],0)\n",
    "data['consommation_level_4'] = round(data['consommation_level_4']/data['months_number'],0)\n",
    "data = reduce_mem_usage(data)\n",
    "# Adjust Column Type\n",
    "data['invoice_date'] = pd.to_datetime(data['invoice_date'])\n",
    "\n",
    "data['tarif_type_str'] = data['tarif_type'].astype(str)\n",
    "\n",
    "data['counter_statue'] = data['counter_statue'].astype(str)\n",
    "data['counter_statue_str'] = data['counter_statue']\n",
    "\n",
    "data['counter_code_str'] = data['counter_code'].astype(str)\n",
    "\n",
    "data['reading_remarque_str'] = data['reading_remarque'].astype(str)\n",
    "data = reduce_mem_usage(data)\n",
    "# Helper Column for Counter Type Split\n",
    "data['GAZ']='GAZ'\n",
    "data['ELEC']='ELEC'\n",
    "\n",
    "data['invoice_date_day'] = data['invoice_date'].dt.day\n",
    "data['invoice_date_month'] = data['invoice_date'].dt.month\n",
    "data['invoice_date_year'] = data['invoice_date'].dt.year\n",
    "\n",
    "data['index_diff'] = data['new_index']-data['old_index']\n",
    "\n",
    "data['invoice_diff']=data.sort_values(by=['client_id','counter_type','invoice_date']).groupby(['client_id','counter_type'])['invoice_date'].diff().dt.days\n",
    "data['con_1_diff']=data.sort_values(by=['client_id','counter_type','counter_number','old_index']).groupby(['client_id','counter_type','counter_number'])['consommation_level_1'].diff()\n",
    "data['con_2_diff']=data.sort_values(by=['client_id','counter_type','counter_number','old_index']).groupby(['client_id','counter_type','counter_number'])['consommation_level_2'].diff()\n",
    "data['con_3_diff']=data.sort_values(by=['client_id','counter_type','counter_number','old_index']).groupby(['client_id','counter_type','counter_number'])['consommation_level_3'].diff()\n",
    "data['con_4_diff']=data.sort_values(by=['client_id','counter_type','counter_number','old_index']).groupby(['client_id','counter_type','counter_number'])['consommation_level_4'].diff()\n",
    "\n",
    "data['index_diff_diff']=data.sort_values(by=['client_id','counter_type','counter_number','old_index']).groupby(['client_id','counter_type','counter_number'])['index_diff'].diff()\n",
    "# Interaction Columns\n",
    "data['number_plus_code'] = data['counter_number'] + data['counter_code']\n",
    "data['number_minus_code'] = data['counter_number'] - data['counter_code']\n",
    "data['number_multi_code'] = data['counter_number'] * data['counter_code']\n",
    "data['number_div_code'] = data['counter_number'] / data['counter_code']\n",
    "data = reduce_mem_usage(data)\n",
    "# Feature Aggregation\n",
    "# Create base dataframe for aggregation\n",
    "base = data[['client_id','ELEC','GAZ']].drop_duplicates()\n",
    "# Create helper columns for quick mapping\n",
    "base['ELEC'] = list(zip(base['client_id'],base['ELEC']))\n",
    "base['GAZ'] = list(zip(base['client_id'],base['GAZ']))\n",
    "\n",
    "num_feature = ['consommation_level_1','consommation_level_2','consommation_level_3','consommation_level_4',\n",
    "               'old_index','new_index','number_plus_code','number_minus_code','number_multi_code','number_div_code']\n",
    "\n",
    "num_diff_feature = ['invoice_diff','con_1_diff','con_2_diff','con_3_diff','con_4_diff','index_diff_diff']\n",
    "\n",
    "cate_feature = ['tarif_type', 'counter_number','counter_statue', 'counter_code', \n",
    "                'reading_remarque','counter_coefficient',\n",
    "                'invoice_date_day','invoice_date_month','invoice_date_year']\n",
    "\n",
    "cate_freq_feature = ['tarif_type_str','counter_statue_str', 'counter_code_str','reading_remarque_str']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for feature in cate_feature:\n",
    "    le.fit(data[feature])\n",
    "    data[feature] = le.transform(data[feature])\n",
    "\n",
    "for feature in (num_feature):\n",
    "    mean_dict = dict(data.groupby(['client_id','counter_type'])[feature].mean())\n",
    "    min_dict = dict(data.groupby(['client_id','counter_type'])[feature].min())\n",
    "    max_dict = dict(data.groupby(['client_id','counter_type'])[feature].max())\n",
    "    std_dict = dict(data.groupby(['client_id','counter_type'])[feature].std())\n",
    "    sum_dict = dict(data.groupby(['client_id','counter_type'])[feature].sum())\n",
    "    for type_ in ['ELEC','GAZ']:\n",
    "        base = reduce_mem_usage(base)\n",
    "        base[f'{feature}_mean_{type_}'] = base[f'{type_}'].map(mean_dict)\n",
    "        base[f'{feature}_min_{type_}'] = base[f'{type_}'].map(min_dict)\n",
    "        base[f'{feature}_max_{type_}'] = base[f'{type_}'].map(max_dict)\n",
    "        base[f'{feature}_std_{type_}'] = base[f'{type_}'].map(std_dict)\n",
    "        base[f'{feature}_sum_{type_}'] = base[f'{type_}'].map(sum_dict)\n",
    "               \n",
    "        base[f'{feature}_range_{type_}'] = base[f'{feature}_max_{type_}'] - base[f'{feature}_min_{type_}']\n",
    "        base[f'{feature}_max_mean_diff_{type_}'] = base[f'{feature}_max_{type_}'] - base[f'{feature}_mean_{type_}']\n",
    "# Numerical Diff Feature aggregation\n",
    "for feature in num_diff_feature:\n",
    "    mean_dict = dict(data.groupby(['client_id','counter_type'])[feature].mean())\n",
    "    min_dict = dict(data.groupby(['client_id','counter_type'])[feature].min())\n",
    "    max_dict = dict(data.groupby(['client_id','counter_type'])[feature].max())\n",
    "    std_dict = dict(data.groupby(['client_id','counter_type'])[feature].std())\n",
    "    sum_dict = dict(data.groupby(['client_id','counter_type'])[feature].sum())\n",
    "    for type_ in ['ELEC','GAZ']:\n",
    "        base = reduce_mem_usage(base)\n",
    "        base[f'{feature}_mean_{type_}'] = base[f'{type_}'].map(mean_dict)\n",
    "        base[f'{feature}_min_{type_}'] = base[f'{type_}'].map(min_dict)\n",
    "        base[f'{feature}_max_{type_}'] = base[f'{type_}'].map(max_dict)\n",
    "        base[f'{feature}_std_{type_}'] = base[f'{type_}'].map(std_dict)\n",
    "        base[f'{feature}_sum_{type_}'] = base[f'{type_}'].map(sum_dict)\n",
    "        base[f'{feature}_range_{type_}'] = base[f'{feature}_max_{type_}'] - base[f'{feature}_min_{type_}']\n",
    "        base[f'{feature}_max_mean_diff_{type_}'] = base[f'{feature}_max_{type_}'] - base[f'{feature}_mean_{type_}']\n",
    "# Categorical Feature aggregation\n",
    "\n",
    "for feature in cate_feature:\n",
    "    nunique_dict = dict(data.groupby(['client_id','counter_type'])[feature].nunique())\n",
    "    mode_dict = dict(data.groupby(['client_id','counter_type'])[feature].agg(lambda x: pd.Series.mode(x)[0]))\n",
    "    for type_ in ['ELEC','GAZ']:\n",
    "        base = reduce_mem_usage(base)\n",
    "        base[f'{feature}_nunique_{type_}'] = base[f'{type_}'].map(nunique_dict)\n",
    "        base[f'{feature}_mode_{type_}'] = base[f'{type_}'].map(mode_dict)\n",
    "# Categorical Feature Frequency Aggregation\n",
    "# 1. Tarif_type\n",
    "tarif_group = data.groupby(['client_id','counter_type','tarif_type_str']).agg(Percent=('tarif_type_str', 'count'))\n",
    "tarif_group = (tarif_group / tarif_group.groupby(level=[0, 1]).transform(\"sum\")).reset_index()\n",
    "\n",
    "tarif_group=tarif_group.set_index(['client_id','counter_type','tarif_type_str']).stack().unstack([2,1])\n",
    "tarif_group.columns = tarif_group.columns.map('_'.join)\n",
    "tarif_group.sort_index(axis=1,inplace=True)\n",
    "tarif_group=tarif_group.add_prefix('Tarif_Type_').reset_index().drop(columns=['level_1']).fillna(0)\n",
    "\n",
    "#  2. Counter_statue\n",
    "statue_group = data.groupby(['client_id','counter_type','counter_statue_str']).agg(Percent=('counter_statue_str', 'count'))\n",
    "statue_group = (statue_group / statue_group.groupby(level=[0, 1]).transform(\"sum\")).reset_index()\n",
    "\n",
    "statue_group=statue_group.set_index(['client_id','counter_type','counter_statue_str']).stack().unstack([2,1])\n",
    "statue_group.columns = statue_group.columns.map('_'.join)\n",
    "statue_group.sort_index(axis=1,inplace=True)\n",
    "statue_group=statue_group.add_prefix('Statue_').reset_index().drop(columns=['level_1']).fillna(0)\n",
    "\n",
    "#  3.  Counter_code  \n",
    "code_group = data.groupby(['client_id','counter_type','counter_code_str']).agg(Percent=('counter_code_str', 'count'))\n",
    "code_group = (code_group / code_group.groupby(level=[0, 1]).transform(\"sum\")).reset_index()\n",
    "\n",
    "code_group=code_group.set_index(['client_id','counter_type','counter_code_str']).stack().unstack([2,1])\n",
    "code_group.columns = code_group.columns.map('_'.join)\n",
    "code_group.sort_index(axis=1,inplace=True)\n",
    "code_group=code_group.add_prefix('Code_').reset_index().drop(columns=['level_1']).fillna(0)\n",
    "\n",
    "#  4.  Reading_remarque \n",
    "rem_group = data.groupby(['client_id','counter_type','reading_remarque_str']).agg(Percent=('reading_remarque_str', 'count'))\n",
    "rem_group = (rem_group / rem_group.groupby(level=[0, 1]).transform(\"sum\")).reset_index()\n",
    "\n",
    "rem_group=rem_group.set_index(['client_id','counter_type','reading_remarque_str']).stack().unstack([2,1])\n",
    "rem_group.columns = rem_group.columns.map('_'.join)\n",
    "rem_group.sort_index(axis=1,inplace=True)\n",
    "rem_group=rem_group.add_prefix('Rem_').reset_index().drop(columns=['level_1']).fillna(0)\n",
    "# Extra Features\n",
    "#  1. Invoice_Count\n",
    "count_group=data.groupby(['client_id','counter_type']).size().reset_index(name='Invoice_Count')\n",
    "count_group=count_group.set_index(['client_id','counter_type']).stack().unstack([2,1])\n",
    "count_group.columns = count_group.columns.map('_'.join)\n",
    "count_group = count_group.reset_index().fillna(0)\n",
    "\n",
    "#  2. Invoice Date Range\n",
    "invoice_range_group=data.groupby(['client_id','counter_type']).agg(first_date=('invoice_date', np.min),\n",
    "                                                               last_date=('invoice_date', np.max)).reset_index()\n",
    "\n",
    "invoice_range_group['date_range'] = (invoice_range_group['last_date']-invoice_range_group['first_date']).dt.days\n",
    "\n",
    "invoice_range_group=invoice_range_group.set_index(['client_id','counter_type']).stack().unstack([2,1])\n",
    "invoice_range_group.columns = invoice_range_group.columns.map('_'.join)\n",
    "invoice_range_group = invoice_range_group.reset_index()\n",
    "# Combine All Features\n",
    "df_list = [base, count_group, invoice_range_group, tarif_group,statue_group,code_group, rem_group]\n",
    "final = df_list[0]\n",
    "for df_ in df_list[1:]:\n",
    "    final = final.merge(df_, how='left',on='client_id')\n",
    "\n",
    "final.drop(columns=['ELEC','GAZ'],inplace=True)\n",
    "final = reduce_mem_usage(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_invoice_agg = final[final['client_id'].str.contains('train')].reset_index(drop=True)\n",
    "test_invoice_agg = final[final['client_id'].str.contains('test')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_client_invoice(client,invoice_agg):\n",
    "    df = client.merge(invoice_agg,how='inner',on='client_id')\n",
    "    \n",
    "    df['date_range_ELEC'] = df['date_range_ELEC'].astype('float64')\n",
    "    df['date_range_GAZ'] = df['date_range_GAZ'].astype('float64')\n",
    "    df['first_date_ELEC'] = pd.to_datetime(df['first_date_ELEC'])\n",
    "    df['last_date_ELEC'] = pd.to_datetime(df['last_date_ELEC'])\n",
    "    df['first_date_GAZ'] = pd.to_datetime(df['first_date_GAZ'])\n",
    "    df['last_date_GAZ'] = pd.to_datetime(df['last_date_GAZ'])\n",
    "    \n",
    "    df['first_invoice_gap_ELEC']  = (df['first_date_ELEC']-df['creation_date']).dt.days\n",
    "    df['last_invoice_gap_ELEC']  = (df['last_date_ELEC']-df['creation_date']).dt.days\n",
    "    df['first_invoice_gap_GAZ']  = (df['first_date_GAZ']-df['creation_date']).dt.days\n",
    "    df['last_invoice_gap_GAZ']  = (df['last_date_GAZ']-df['creation_date']).dt.days\n",
    "    df.drop(columns = ['client_id','first_date_ELEC','last_date_ELEC','first_date_GAZ','last_date_GAZ','creation_date'],inplace=True)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58069, 383)\n",
      "Mem. usage decreased to 56.65 Mb (3.8% reduction)\n",
      "(135488, 384)\n",
      "Mem. usage decreased to 132.44 Mb (3.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "test_df = reduce_mem_usage(merge_client_invoice(client_test,test_invoice_agg).fillna(0))\n",
    "train_df = reduce_mem_usage(merge_client_invoice(client_train,train_invoice_agg).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds = train_test_split(train_df, test_size = 0.2)\n",
    "train_labels = np.array(train_ds.target)\n",
    "train_features = train_ds.drop([\"target\"], axis = 1)\n",
    "val_labels = np.array(val_ds.target)\n",
    "val_features = val_ds.drop([\"target\"], axis = 1)\n",
    "bool_train_labels = train_labels != 0\n",
    "scaler = StandardScaler()\n",
    "# train_ds = pd.DataFrame(pd.concat([pd.DataFrame(scaler.fit_transform(train_ds.drop([\"target\"], axis = 1))), pd.DataFrame(train_ds[\"target\"])], axis = 1),columns = train_ds.columns)\n",
    "# val_ds = pd.DataFrame(pd.concat([pd.DataFrame(scaler.transform(val_ds.drop([\"target\"], axis = 1))), pd.DataFrame(val_ds[\"target\"])], axis = 1),columns = val_ds.columns)\n",
    "# test_df = pd.DataFrame(scaler.transform(test_df),columns = test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_bias = np.log(train_df[train_df.target == 1].shape[0]/train_df[train_df.target == 0].shape[0])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  labels = df.pop('target')\n",
    "  df = {key: np.array(value)[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_ds = df_to_dataset(train_ds, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_ds, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Perform normalization and onehot encoding on numeric and categorical variables respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Model formulation. The most important layers are the first layer, dropout and final dense layer. The rest are nice-to-have and seem to improve performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-16T21:50:59.874434Z",
     "iopub.status.busy": "2023-12-16T21:50:59.873710Z",
     "iopub.status.idle": "2023-12-16T21:50:59.942400Z",
     "shell.execute_reply": "2023-12-16T21:50:59.941905Z",
     "shell.execute_reply.started": "2023-12-16T21:50:59.874381Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">786,432</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,196,352</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │    \u001b[38;5;34m786,432\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │  \u001b[38;5;34m4,196,352\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │  \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │      \u001b[38;5;34m1,025\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,081,985</span> (27.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,081,985\u001b[0m (27.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,081,985</span> (27.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,081,985\u001b[0m (27.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "      keras.layers.Dense(2048, activation='elu',kernel_initializer='normal',input_shape=(383,)),\n",
    "      keras.layers.Dense(2048, activation='sigmoid',kernel_initializer='normal'),\n",
    "      keras.layers.Dense(1024, activation='sigmoid',kernel_initializer='normal'),\n",
    "      #keras.layers.Dense(256, activation='sigmoid',kernel_initializer='normal'),\n",
    "      #keras.layers.Dense(128, activation='sigmoid',kernel_initializer='normal'),\n",
    "      #keras.layers.Dense(64, activation='sigmoid',kernel_initializer='normal'),\n",
    "      #keras.layers.Dense(32, activation='sigmoid',kernel_initializer='normal'),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1,kernel_initializer='normal',bias_initializer=output_bias,activation='sigmoid'),\n",
    "   ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[\"AUC\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-16T21:51:00.935763Z",
     "iopub.status.busy": "2023-12-16T21:51:00.935034Z",
     "iopub.status.idle": "2023-12-16T21:51:00.978875Z",
     "shell.execute_reply": "2023-12-16T21:51:00.978288Z",
     "shell.execute_reply.started": "2023-12-16T21:51:00.935712Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-16T21:51:01.710224Z",
     "iopub.status.busy": "2023-12-16T21:51:01.709527Z",
     "iopub.status.idle": "2023-12-16T22:13:47.707359Z",
     "shell.execute_reply": "2023-12-16T22:13:47.706416Z",
     "shell.execute_reply.started": "2023-12-16T21:51:01.710156Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 85ms/step - AUC: 0.6784 - loss: 0.2126 - val_AUC: 0.7656 - val_loss: 0.1892\n",
      "Epoch 2/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 81ms/step - AUC: 0.7225 - loss: 0.2002 - val_AUC: 0.7747 - val_loss: 0.1953\n",
      "Epoch 3/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 84ms/step - AUC: 0.7285 - loss: 0.1934 - val_AUC: 0.7529 - val_loss: 0.2061\n",
      "Epoch 4/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 81ms/step - AUC: 0.6976 - loss: 0.1963 - val_AUC: 0.7679 - val_loss: 0.1877\n",
      "Epoch 5/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 78ms/step - AUC: 0.7292 - loss: 0.1967 - val_AUC: 0.7720 - val_loss: 0.1885\n",
      "Epoch 6/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 82ms/step - AUC: 0.7173 - loss: 0.1953 - val_AUC: 0.7760 - val_loss: 0.1899\n",
      "Epoch 7/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 80ms/step - AUC: 0.7198 - loss: 0.1943 - val_AUC: 0.7680 - val_loss: 0.1868\n",
      "Epoch 8/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 78ms/step - AUC: 0.7202 - loss: 0.1981 - val_AUC: 0.7749 - val_loss: 0.1855\n",
      "Epoch 9/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 80ms/step - AUC: 0.7156 - loss: 0.1944 - val_AUC: 0.7691 - val_loss: 0.1904\n",
      "Epoch 10/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 83ms/step - AUC: 0.7212 - loss: 0.1910 - val_AUC: 0.7397 - val_loss: 0.1943\n",
      "Epoch 11/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 86ms/step - AUC: 0.7006 - loss: 0.2018 - val_AUC: 0.7577 - val_loss: 0.1901\n",
      "Epoch 12/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 83ms/step - AUC: 0.7074 - loss: 0.1988 - val_AUC: 0.7572 - val_loss: 0.1914\n",
      "Epoch 13/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 80ms/step - AUC: 0.7061 - loss: 0.1979 - val_AUC: 0.7530 - val_loss: 0.1897\n",
      "Epoch 14/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 86ms/step - AUC: 0.7081 - loss: 0.1961 - val_AUC: 0.7481 - val_loss: 0.1937\n",
      "Epoch 15/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 78ms/step - AUC: 0.6949 - loss: 0.1965 - val_AUC: 0.7435 - val_loss: 0.1942\n",
      "Epoch 16/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 81ms/step - AUC: 0.7042 - loss: 0.1972 - val_AUC: 0.7531 - val_loss: 0.1934\n",
      "Epoch 17/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 80ms/step - AUC: 0.7028 - loss: 0.1990 - val_AUC: 0.7625 - val_loss: 0.1883\n",
      "Epoch 18/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 76ms/step - AUC: 0.7092 - loss: 0.1966 - val_AUC: 0.7669 - val_loss: 0.1911\n",
      "Epoch 19/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 75ms/step - AUC: 0.7178 - loss: 0.1989 - val_AUC: 0.7688 - val_loss: 0.1883\n",
      "Epoch 20/20\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 77ms/step - AUC: 0.7138 - loss: 0.1959 - val_AUC: 0.7686 - val_loss: 0.1935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x55d1abe50>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-16T22:13:47.709955Z",
     "iopub.status.busy": "2023-12-16T22:13:47.709682Z",
     "iopub.status.idle": "2023-12-16T22:29:42.422358Z",
     "shell.execute_reply": "2023-12-16T22:29:42.421790Z",
     "shell.execute_reply.started": "2023-12-16T22:13:47.709929Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 120ms/step - AUC: 0.7276 - loss: 0.1934 - val_AUC: 0.7603 - val_loss: 0.1953\n",
      "Epoch 2/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 113ms/step - AUC: 0.7154 - loss: 0.1947 - val_AUC: 0.7708 - val_loss: 0.1855\n",
      "Epoch 3/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 110ms/step - AUC: 0.7290 - loss: 0.1959 - val_AUC: 0.7512 - val_loss: 0.1908\n",
      "Epoch 4/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 109ms/step - AUC: 0.7159 - loss: 0.1943 - val_AUC: 0.7561 - val_loss: 0.1893\n",
      "Epoch 5/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 131ms/step - AUC: 0.7045 - loss: 0.1976 - val_AUC: 0.7603 - val_loss: 0.1891\n",
      "Epoch 6/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 119ms/step - AUC: 0.7113 - loss: 0.1979 - val_AUC: 0.7399 - val_loss: 0.1896\n",
      "Epoch 7/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 110ms/step - AUC: 0.6935 - loss: 0.1999 - val_AUC: 0.7405 - val_loss: 0.2015\n",
      "Epoch 8/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 109ms/step - AUC: 0.6625 - loss: 0.2049 - val_AUC: 0.7368 - val_loss: 0.1932\n",
      "Epoch 9/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 112ms/step - AUC: 0.6803 - loss: 0.2003 - val_AUC: 0.6720 - val_loss: 0.2007\n",
      "Epoch 10/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 113ms/step - AUC: 0.6336 - loss: 0.2045 - val_AUC: 0.6825 - val_loss: 0.1991\n",
      "Epoch 11/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 110ms/step - AUC: 0.6406 - loss: 0.2029 - val_AUC: 0.6937 - val_loss: 0.2029\n",
      "Epoch 12/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 111ms/step - AUC: 0.6271 - loss: 0.2029 - val_AUC: 0.6746 - val_loss: 0.1975\n",
      "Epoch 13/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 111ms/step - AUC: 0.6200 - loss: 0.2038 - val_AUC: 0.6647 - val_loss: 0.1967\n",
      "Epoch 14/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 111ms/step - AUC: 0.6301 - loss: 0.2028 - val_AUC: 0.6640 - val_loss: 0.1984\n",
      "Epoch 15/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 111ms/step - AUC: 0.6391 - loss: 0.2019 - val_AUC: 0.6769 - val_loss: 0.1980\n",
      "Epoch 16/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 110ms/step - AUC: 0.6374 - loss: 0.2036 - val_AUC: 0.7071 - val_loss: 0.1942\n",
      "Epoch 17/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 110ms/step - AUC: 0.6380 - loss: 0.2018 - val_AUC: 0.6574 - val_loss: 0.1975\n",
      "Epoch 18/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 110ms/step - AUC: 0.6308 - loss: 0.2035 - val_AUC: 0.6840 - val_loss: 0.1965\n",
      "Epoch 19/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 110ms/step - AUC: 0.6260 - loss: 0.2037 - val_AUC: 0.6708 - val_loss: 0.1952\n",
      "Epoch 20/20\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 110ms/step - AUC: 0.6332 - loss: 0.2013 - val_AUC: 0.6760 - val_loss: 0.1970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x55d1fd490>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=256,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-16T22:29:42.423643Z",
     "iopub.status.busy": "2023-12-16T22:29:42.423281Z",
     "iopub.status.idle": "2023-12-17T00:22:10.700170Z",
     "shell.execute_reply": "2023-12-17T00:22:10.699284Z",
     "shell.execute_reply.started": "2023-12-16T22:29:42.423621Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1633s\u001b[0m 8s/step - AUC: 0.6308 - loss: 0.2029 - val_AUC: 0.6695 - val_loss: 0.1985\n",
      "Epoch 2/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 198ms/step - AUC: 0.6359 - loss: 0.2018 - val_AUC: 0.6700 - val_loss: 0.1968\n",
      "Epoch 3/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 187ms/step - AUC: 0.6402 - loss: 0.2032 - val_AUC: 0.6696 - val_loss: 0.1954\n",
      "Epoch 4/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 189ms/step - AUC: 0.6472 - loss: 0.2003 - val_AUC: 0.6700 - val_loss: 0.1960\n",
      "Epoch 5/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 190ms/step - AUC: 0.6331 - loss: 0.2037 - val_AUC: 0.6702 - val_loss: 0.1968\n",
      "Epoch 6/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4356s\u001b[0m 21s/step - AUC: 0.6361 - loss: 0.2011 - val_AUC: 0.6782 - val_loss: 0.1960\n",
      "Epoch 7/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 203ms/step - AUC: 0.6440 - loss: 0.2043 - val_AUC: 0.6784 - val_loss: 0.1951\n",
      "Epoch 8/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 206ms/step - AUC: 0.6462 - loss: 0.2010 - val_AUC: 0.6789 - val_loss: 0.1954\n",
      "Epoch 9/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 201ms/step - AUC: 0.6303 - loss: 0.2030 - val_AUC: 0.6708 - val_loss: 0.1953\n",
      "Epoch 10/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 200ms/step - AUC: 0.6359 - loss: 0.2027 - val_AUC: 0.6794 - val_loss: 0.1948\n",
      "Epoch 11/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 197ms/step - AUC: 0.6464 - loss: 0.1983 - val_AUC: 0.6787 - val_loss: 0.1948\n",
      "Epoch 12/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 198ms/step - AUC: 0.6315 - loss: 0.2042 - val_AUC: 0.6803 - val_loss: 0.1936\n",
      "Epoch 13/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 203ms/step - AUC: 0.6381 - loss: 0.2046 - val_AUC: 0.6693 - val_loss: 0.2004\n",
      "Epoch 14/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 199ms/step - AUC: 0.6315 - loss: 0.2034 - val_AUC: 0.6797 - val_loss: 0.1950\n",
      "Epoch 15/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 196ms/step - AUC: 0.6386 - loss: 0.2026 - val_AUC: 0.6776 - val_loss: 0.1948\n",
      "Epoch 16/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 196ms/step - AUC: 0.6463 - loss: 0.1983 - val_AUC: 0.6716 - val_loss: 0.1977\n",
      "Epoch 17/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 192ms/step - AUC: 0.6405 - loss: 0.2040 - val_AUC: 0.6794 - val_loss: 0.1955\n",
      "Epoch 18/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 201ms/step - AUC: 0.6438 - loss: 0.2009 - val_AUC: 0.6777 - val_loss: 0.1947\n",
      "Epoch 19/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 205ms/step - AUC: 0.6476 - loss: 0.1994 - val_AUC: 0.6784 - val_loss: 0.1967\n",
      "Epoch 20/20\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 218ms/step - AUC: 0.6420 - loss: 0.2022 - val_AUC: 0.6795 - val_loss: 0.1947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x58bde9790>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=512,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-12-17T00:22:10.703224Z",
     "iopub.status.busy": "2023-12-17T00:22:10.702982Z",
     "iopub.status.idle": "2023-12-17T00:35:38.272976Z",
     "shell.execute_reply": "2023-12-17T00:35:38.272084Z",
     "shell.execute_reply.started": "2023-12-17T00:22:10.703199Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 418ms/step - AUC: 0.6528 - loss: 0.1969 - val_AUC: 0.6806 - val_loss: 0.1928\n",
      "Epoch 2/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 422ms/step - AUC: 0.6427 - loss: 0.2026 - val_AUC: 0.6797 - val_loss: 0.1940\n",
      "Epoch 3/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 422ms/step - AUC: 0.6491 - loss: 0.1993 - val_AUC: 0.6796 - val_loss: 0.1945\n",
      "Epoch 4/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 417ms/step - AUC: 0.6412 - loss: 0.2011 - val_AUC: 0.6801 - val_loss: 0.1923\n",
      "Epoch 5/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 414ms/step - AUC: 0.6451 - loss: 0.2008 - val_AUC: 0.6805 - val_loss: 0.1922\n",
      "Epoch 6/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 417ms/step - AUC: 0.6463 - loss: 0.1985 - val_AUC: 0.6813 - val_loss: 0.1929\n",
      "Epoch 7/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 416ms/step - AUC: 0.6417 - loss: 0.2010 - val_AUC: 0.6809 - val_loss: 0.1919\n",
      "Epoch 8/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 405ms/step - AUC: 0.6521 - loss: 0.1999 - val_AUC: 0.6806 - val_loss: 0.1919\n",
      "Epoch 9/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 366ms/step - AUC: 0.6372 - loss: 0.2010 - val_AUC: 0.6805 - val_loss: 0.1927\n",
      "Epoch 10/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 370ms/step - AUC: 0.6463 - loss: 0.2000 - val_AUC: 0.6795 - val_loss: 0.1945\n",
      "Epoch 11/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 367ms/step - AUC: 0.6508 - loss: 0.1970 - val_AUC: 0.6798 - val_loss: 0.1935\n",
      "Epoch 12/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 359ms/step - AUC: 0.6408 - loss: 0.2004 - val_AUC: 0.6798 - val_loss: 0.1933\n",
      "Epoch 13/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 367ms/step - AUC: 0.6394 - loss: 0.2023 - val_AUC: 0.6810 - val_loss: 0.1927\n",
      "Epoch 14/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 356ms/step - AUC: 0.6379 - loss: 0.1977 - val_AUC: 0.6801 - val_loss: 0.1932\n",
      "Epoch 15/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 369ms/step - AUC: 0.6520 - loss: 0.1971 - val_AUC: 0.6806 - val_loss: 0.1965\n",
      "Epoch 16/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 339ms/step - AUC: 0.6520 - loss: 0.2018 - val_AUC: 0.6793 - val_loss: 0.1935\n",
      "Epoch 17/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 345ms/step - AUC: 0.6413 - loss: 0.1985 - val_AUC: 0.6797 - val_loss: 0.1918\n",
      "Epoch 18/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 371ms/step - AUC: 0.6541 - loss: 0.1999 - val_AUC: 0.6795 - val_loss: 0.1972\n",
      "Epoch 19/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 345ms/step - AUC: 0.6541 - loss: 0.2013 - val_AUC: 0.6814 - val_loss: 0.1925\n",
      "Epoch 20/20\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 341ms/step - AUC: 0.6455 - loss: 0.2029 - val_AUC: 0.6804 - val_loss: 0.1921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x41222ce10>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=1024,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T02:54:14.222965Z",
     "iopub.status.busy": "2023-12-18T02:54:14.222255Z",
     "iopub.status.idle": "2023-12-18T03:10:23.627608Z",
     "shell.execute_reply": "2023-12-18T03:10:23.626868Z",
     "shell.execute_reply.started": "2023-12-18T02:54:14.222915Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4945.906| val_0_unsup_loss_numpy: 59912.22265625|  0:00:15s\n",
      "epoch 1  | loss: 2873.67767| val_0_unsup_loss_numpy: 45900.0234375|  0:00:29s\n",
      "epoch 2  | loss: 1792.92964| val_0_unsup_loss_numpy: 15902.4423828125|  0:00:46s\n",
      "epoch 3  | loss: 1329.70732| val_0_unsup_loss_numpy: 11145.7001953125|  0:01:01s\n",
      "epoch 4  | loss: 760.30628| val_0_unsup_loss_numpy: 13718.3095703125|  0:01:15s\n",
      "epoch 5  | loss: 576.21725| val_0_unsup_loss_numpy: 2647.457275390625|  0:01:30s\n",
      "epoch 6  | loss: 311.50916| val_0_unsup_loss_numpy: 1614.2958984375|  0:01:44s\n",
      "epoch 7  | loss: 220.35642| val_0_unsup_loss_numpy: 599.8854370117188|  0:01:59s\n",
      "epoch 8  | loss: 182.82305| val_0_unsup_loss_numpy: 848.2854614257812|  0:02:15s\n",
      "epoch 9  | loss: 170.95851| val_0_unsup_loss_numpy: 1011.438232421875|  0:02:31s\n",
      "epoch 10 | loss: 159.76219| val_0_unsup_loss_numpy: 1056.9515380859375|  0:02:45s\n",
      "epoch 11 | loss: 160.13637| val_0_unsup_loss_numpy: 493.1054382324219|  0:03:00s\n",
      "epoch 12 | loss: 158.43062| val_0_unsup_loss_numpy: 235.90231323242188|  0:03:15s\n",
      "epoch 13 | loss: 157.72043| val_0_unsup_loss_numpy: 220.97242736816406|  0:03:29s\n",
      "epoch 14 | loss: 157.17624| val_0_unsup_loss_numpy: 209.911376953125|  0:03:43s\n",
      "epoch 15 | loss: 156.50015| val_0_unsup_loss_numpy: 194.73269653320312|  0:03:58s\n",
      "epoch 16 | loss: 157.48864| val_0_unsup_loss_numpy: 189.7657928466797|  0:04:12s\n",
      "epoch 17 | loss: 155.6991| val_0_unsup_loss_numpy: 184.93106079101562|  0:04:26s\n",
      "epoch 18 | loss: 155.81268| val_0_unsup_loss_numpy: 414.04803466796875|  0:04:41s\n",
      "epoch 19 | loss: 154.42561| val_0_unsup_loss_numpy: 635.1439208984375|  0:04:55s\n",
      "epoch 20 | loss: 155.65939| val_0_unsup_loss_numpy: 212.88296508789062|  0:05:09s\n",
      "epoch 21 | loss: 154.73901| val_0_unsup_loss_numpy: 179.48245239257812|  0:06:31s\n",
      "epoch 22 | loss: 153.78257| val_0_unsup_loss_numpy: 568.457275390625|  0:06:43s\n",
      "epoch 23 | loss: 152.69753| val_0_unsup_loss_numpy: 192.06361389160156|  0:06:54s\n",
      "epoch 24 | loss: 152.73243| val_0_unsup_loss_numpy: 253.73768615722656|  0:07:05s\n",
      "epoch 25 | loss: 151.3136| val_0_unsup_loss_numpy: 175.74513244628906|  0:07:15s\n",
      "epoch 26 | loss: 153.25625| val_0_unsup_loss_numpy: 329.42333984375|  0:07:26s\n",
      "epoch 27 | loss: 152.32679| val_0_unsup_loss_numpy: 681.3358154296875|  0:07:36s\n",
      "epoch 28 | loss: 149.58004| val_0_unsup_loss_numpy: 183.3004608154297|  0:07:47s\n",
      "epoch 29 | loss: 154.42919| val_0_unsup_loss_numpy: 181.14120483398438|  0:07:58s\n",
      "epoch 30 | loss: 151.36039| val_0_unsup_loss_numpy: 189.85264587402344|  0:08:08s\n",
      "epoch 31 | loss: 152.81076| val_0_unsup_loss_numpy: 303.9954528808594|  0:08:19s\n",
      "epoch 32 | loss: 155.31657| val_0_unsup_loss_numpy: 182.25755310058594|  0:08:30s\n",
      "epoch 33 | loss: 149.45038| val_0_unsup_loss_numpy: 200.88479614257812|  0:08:40s\n",
      "epoch 34 | loss: 152.06474| val_0_unsup_loss_numpy: 197.17486572265625|  0:08:51s\n",
      "epoch 35 | loss: 159.59233| val_0_unsup_loss_numpy: 193.1390838623047|  0:09:02s\n",
      "epoch 36 | loss: 145.26661| val_0_unsup_loss_numpy: 178.94947814941406|  0:09:12s\n",
      "epoch 37 | loss: 147.95288| val_0_unsup_loss_numpy: 183.91758728027344|  0:09:23s\n",
      "epoch 38 | loss: 147.19059| val_0_unsup_loss_numpy: 186.0423126220703|  0:09:34s\n",
      "epoch 39 | loss: 149.06355| val_0_unsup_loss_numpy: 199.0040740966797|  0:09:44s\n",
      "epoch 40 | loss: 148.15003| val_0_unsup_loss_numpy: 312.78448486328125|  0:09:55s\n",
      "epoch 41 | loss: 149.12139| val_0_unsup_loss_numpy: 202.22044372558594|  0:10:06s\n",
      "epoch 42 | loss: 146.53126| val_0_unsup_loss_numpy: 201.9315643310547|  0:10:16s\n",
      "epoch 43 | loss: 148.11069| val_0_unsup_loss_numpy: 234.06553649902344|  0:10:27s\n",
      "epoch 44 | loss: 145.04286| val_0_unsup_loss_numpy: 203.27505493164062|  0:10:38s\n",
      "epoch 45 | loss: 146.50744| val_0_unsup_loss_numpy: 192.65786743164062|  0:10:48s\n",
      "epoch 46 | loss: 144.32602| val_0_unsup_loss_numpy: 235.8790740966797|  0:10:59s\n",
      "epoch 47 | loss: 138.48675| val_0_unsup_loss_numpy: 189.31268310546875|  0:11:10s\n",
      "epoch 48 | loss: 141.54097| val_0_unsup_loss_numpy: 243.2788543701172|  0:11:20s\n",
      "epoch 49 | loss: 142.06722| val_0_unsup_loss_numpy: 206.45741271972656|  0:11:31s\n",
      "epoch 50 | loss: 137.2098| val_0_unsup_loss_numpy: 215.27427673339844|  0:11:42s\n",
      "epoch 51 | loss: 133.18248| val_0_unsup_loss_numpy: 237.00767517089844|  0:11:52s\n",
      "epoch 52 | loss: 147.57643| val_0_unsup_loss_numpy: 216.05503845214844|  0:12:03s\n",
      "epoch 53 | loss: 153.46699| val_0_unsup_loss_numpy: 215.51898193359375|  0:12:14s\n",
      "epoch 54 | loss: 143.68507| val_0_unsup_loss_numpy: 177.4845733642578|  0:12:24s\n",
      "epoch 55 | loss: 203.08673| val_0_unsup_loss_numpy: 224.1573944091797|  0:12:35s\n",
      "epoch 56 | loss: 139.8619| val_0_unsup_loss_numpy: 334.9551696777344|  0:12:46s\n",
      "epoch 57 | loss: 155.48846| val_0_unsup_loss_numpy: 217.6971435546875|  0:12:56s\n",
      "epoch 58 | loss: 128.69194| val_0_unsup_loss_numpy: 194.70785522460938|  0:13:07s\n",
      "epoch 59 | loss: 134.0987| val_0_unsup_loss_numpy: 198.3526611328125|  0:13:18s\n",
      "epoch 60 | loss: 133.85274| val_0_unsup_loss_numpy: 285.01593017578125|  0:13:28s\n",
      "epoch 61 | loss: 148.66681| val_0_unsup_loss_numpy: 200.41427612304688|  0:13:39s\n",
      "epoch 62 | loss: 125.54821| val_0_unsup_loss_numpy: 211.7477264404297|  0:13:50s\n",
      "epoch 63 | loss: 132.27115| val_0_unsup_loss_numpy: 221.9930419921875|  0:14:00s\n",
      "epoch 64 | loss: 134.57269| val_0_unsup_loss_numpy: 206.35342407226562|  0:14:11s\n",
      "epoch 65 | loss: 133.07352| val_0_unsup_loss_numpy: 201.37298583984375|  0:14:22s\n",
      "epoch 66 | loss: 127.12497| val_0_unsup_loss_numpy: 221.17945861816406|  0:14:32s\n",
      "epoch 67 | loss: 130.49675| val_0_unsup_loss_numpy: 192.2991943359375|  0:14:43s\n",
      "epoch 68 | loss: 129.45405| val_0_unsup_loss_numpy: 186.6746063232422|  0:14:54s\n",
      "epoch 69 | loss: 121.27662| val_0_unsup_loss_numpy: 194.60006713867188|  0:15:04s\n",
      "epoch 70 | loss: 123.13786| val_0_unsup_loss_numpy: 195.50875854492188|  0:15:15s\n",
      "epoch 71 | loss: 137.08715| val_0_unsup_loss_numpy: 206.8875274658203|  0:15:26s\n",
      "epoch 72 | loss: 121.19708| val_0_unsup_loss_numpy: 222.4467010498047|  0:15:37s\n",
      "epoch 73 | loss: 120.7019| val_0_unsup_loss_numpy: 192.82249450683594|  0:15:47s\n",
      "epoch 74 | loss: 126.58633| val_0_unsup_loss_numpy: 209.6181640625|  0:15:58s\n",
      "epoch 75 | loss: 127.75603| val_0_unsup_loss_numpy: 208.9886932373047|  0:16:09s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 175.74513244628906\n"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model_no_preproc = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    )\n",
    "\n",
    "# fit the model\n",
    "unsupervised_model_no_preproc.fit(\n",
    "    train_features.values,\n",
    "    eval_set=[val_features.values],\n",
    "    max_epochs=1000 , patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.8,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T03:10:23.638889Z",
     "iopub.status.busy": "2023-12-18T03:10:23.638605Z",
     "iopub.status.idle": "2023-12-18T03:10:27.382964Z",
     "shell.execute_reply": "2023-12-18T03:10:27.382684Z",
     "shell.execute_reply.started": "2023-12-18T03:10:23.638869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./test_pretrain2.zip\n"
     ]
    }
   ],
   "source": [
    "# Make reconstruction from a dataset\n",
    "reconstructed_X, embedded_X = unsupervised_model_no_preproc.predict(train_features.values,)\n",
    "assert(reconstructed_X.shape==embedded_X.shape)\n",
    "\n",
    "unsupervised_model_no_preproc.save_model('./test_pretrain2')\n",
    "loaded_pretrain = TabNetPretrainer()\n",
    "loaded_pretrain.load_model('./test_pretrain2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T03:10:27.383481Z",
     "iopub.status.busy": "2023-12-18T03:10:27.383391Z",
     "iopub.status.idle": "2023-12-18T03:10:27.385894Z",
     "shell.execute_reply": "2023-12-18T03:10:27.385652Z",
     "shell.execute_reply.started": "2023-12-18T03:10:27.383471Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf2_preproc = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax' # This will be overwritten if using pretrain model\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T03:10:27.386838Z",
     "iopub.status.busy": "2023-12-18T03:10:27.386757Z",
     "iopub.status.idle": "2023-12-18T03:29:48.768330Z",
     "shell.execute_reply": "2023-12-18T03:29:48.767738Z",
     "shell.execute_reply.started": "2023-12-18T03:10:27.386831Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70578 | train_accuracy: 0.38254 | train_auc: 0.59549 | valid_accuracy: 0.38442 | valid_auc: 0.60294 |  0:00:12s\n",
      "epoch 1  | loss: 0.67806 | train_accuracy: 0.59203 | train_auc: 0.65696 | valid_accuracy: 0.58949 | valid_auc: 0.67017 |  0:00:25s\n",
      "epoch 2  | loss: 0.65512 | train_accuracy: 0.63884 | train_auc: 0.70863 | valid_accuracy: 0.63983 | valid_auc: 0.71901 |  0:00:38s\n",
      "epoch 3  | loss: 0.62112 | train_accuracy: 0.74997 | train_auc: 0.76651 | valid_accuracy: 0.75006 | valid_auc: 0.76712 |  0:00:51s\n",
      "epoch 4  | loss: 0.58415 | train_accuracy: 0.73968 | train_auc: 0.78339 | valid_accuracy: 0.74112 | valid_auc: 0.78754 |  0:01:04s\n",
      "epoch 5  | loss: 0.56419 | train_accuracy: 0.77417 | train_auc: 0.79916 | valid_accuracy: 0.77714 | valid_auc: 0.80432 |  0:01:17s\n",
      "epoch 6  | loss: 0.549   | train_accuracy: 0.80387 | train_auc: 0.81152 | valid_accuracy: 0.80571 | valid_auc: 0.81791 |  0:01:30s\n",
      "epoch 7  | loss: 0.5367  | train_accuracy: 0.81127 | train_auc: 0.82423 | valid_accuracy: 0.81117 | valid_auc: 0.8278  |  0:01:42s\n",
      "epoch 8  | loss: 0.51937 | train_accuracy: 0.81369 | train_auc: 0.83741 | valid_accuracy: 0.81323 | valid_auc: 0.84057 |  0:01:55s\n",
      "epoch 9  | loss: 0.50848 | train_accuracy: 0.80932 | train_auc: 0.84455 | valid_accuracy: 0.80969 | valid_auc: 0.84744 |  0:02:08s\n",
      "epoch 10 | loss: 0.50117 | train_accuracy: 0.80407 | train_auc: 0.84912 | valid_accuracy: 0.8053  | valid_auc: 0.85265 |  0:02:20s\n",
      "epoch 11 | loss: 0.49206 | train_accuracy: 0.80289 | train_auc: 0.85208 | valid_accuracy: 0.80404 | valid_auc: 0.85545 |  0:02:33s\n",
      "epoch 12 | loss: 0.4899  | train_accuracy: 0.80046 | train_auc: 0.85472 | valid_accuracy: 0.80131 | valid_auc: 0.85854 |  0:02:46s\n",
      "epoch 13 | loss: 0.48403 | train_accuracy: 0.78743 | train_auc: 0.85836 | valid_accuracy: 0.78836 | valid_auc: 0.86312 |  0:02:59s\n",
      "epoch 14 | loss: 0.47765 | train_accuracy: 0.79247 | train_auc: 0.86111 | valid_accuracy: 0.79305 | valid_auc: 0.86473 |  0:03:12s\n",
      "epoch 15 | loss: 0.47735 | train_accuracy: 0.79935 | train_auc: 0.86399 | valid_accuracy: 0.79932 | valid_auc: 0.8675  |  0:03:24s\n",
      "epoch 16 | loss: 0.47004 | train_accuracy: 0.80073 | train_auc: 0.86631 | valid_accuracy: 0.80124 | valid_auc: 0.8701  |  0:03:37s\n",
      "epoch 17 | loss: 0.47023 | train_accuracy: 0.80529 | train_auc: 0.86815 | valid_accuracy: 0.80563 | valid_auc: 0.87199 |  0:03:50s\n",
      "epoch 18 | loss: 0.46507 | train_accuracy: 0.8086  | train_auc: 0.87074 | valid_accuracy: 0.80851 | valid_auc: 0.87382 |  0:04:03s\n",
      "epoch 19 | loss: 0.46157 | train_accuracy: 0.80328 | train_auc: 0.87283 | valid_accuracy: 0.80331 | valid_auc: 0.87546 |  0:04:15s\n",
      "epoch 20 | loss: 0.45648 | train_accuracy: 0.81407 | train_auc: 0.87469 | valid_accuracy: 0.81526 | valid_auc: 0.87678 |  0:04:28s\n",
      "epoch 21 | loss: 0.45568 | train_accuracy: 0.81162 | train_auc: 0.87585 | valid_accuracy: 0.81113 | valid_auc: 0.87741 |  0:04:40s\n",
      "epoch 22 | loss: 0.4537  | train_accuracy: 0.80816 | train_auc: 0.87686 | valid_accuracy: 0.80722 | valid_auc: 0.87831 |  0:04:53s\n",
      "epoch 23 | loss: 0.4499  | train_accuracy: 0.80997 | train_auc: 0.87851 | valid_accuracy: 0.80928 | valid_auc: 0.87913 |  0:05:05s\n",
      "epoch 24 | loss: 0.44817 | train_accuracy: 0.80931 | train_auc: 0.88004 | valid_accuracy: 0.80851 | valid_auc: 0.87991 |  0:05:18s\n",
      "epoch 25 | loss: 0.4445  | train_accuracy: 0.81446 | train_auc: 0.88081 | valid_accuracy: 0.81393 | valid_auc: 0.88043 |  0:05:31s\n",
      "epoch 26 | loss: 0.44246 | train_accuracy: 0.81374 | train_auc: 0.8822  | valid_accuracy: 0.8129  | valid_auc: 0.88142 |  0:05:44s\n",
      "epoch 27 | loss: 0.44159 | train_accuracy: 0.81648 | train_auc: 0.88349 | valid_accuracy: 0.81667 | valid_auc: 0.8819  |  0:05:56s\n",
      "epoch 28 | loss: 0.44147 | train_accuracy: 0.81481 | train_auc: 0.88451 | valid_accuracy: 0.81272 | valid_auc: 0.8828  |  0:06:09s\n",
      "epoch 29 | loss: 0.43533 | train_accuracy: 0.8152  | train_auc: 0.88649 | valid_accuracy: 0.81441 | valid_auc: 0.88438 |  0:06:21s\n",
      "epoch 30 | loss: 0.43343 | train_accuracy: 0.82033 | train_auc: 0.88784 | valid_accuracy: 0.81943 | valid_auc: 0.88362 |  0:06:34s\n",
      "epoch 31 | loss: 0.43351 | train_accuracy: 0.82153 | train_auc: 0.88853 | valid_accuracy: 0.82102 | valid_auc: 0.88383 |  0:06:47s\n",
      "epoch 32 | loss: 0.4327  | train_accuracy: 0.81498 | train_auc: 0.88925 | valid_accuracy: 0.81438 | valid_auc: 0.88499 |  0:07:00s\n",
      "epoch 33 | loss: 0.42778 | train_accuracy: 0.81678 | train_auc: 0.8907  | valid_accuracy: 0.81589 | valid_auc: 0.88494 |  0:07:12s\n",
      "epoch 34 | loss: 0.4252  | train_accuracy: 0.80376 | train_auc: 0.89096 | valid_accuracy: 0.80283 | valid_auc: 0.8855  |  0:07:25s\n",
      "epoch 35 | loss: 0.42526 | train_accuracy: 0.82463 | train_auc: 0.89196 | valid_accuracy: 0.82246 | valid_auc: 0.88571 |  0:07:38s\n",
      "epoch 36 | loss: 0.42613 | train_accuracy: 0.82366 | train_auc: 0.89239 | valid_accuracy: 0.82165 | valid_auc: 0.88548 |  0:07:50s\n",
      "epoch 37 | loss: 0.42222 | train_accuracy: 0.81843 | train_auc: 0.89341 | valid_accuracy: 0.81788 | valid_auc: 0.88556 |  0:08:03s\n",
      "epoch 38 | loss: 0.4217  | train_accuracy: 0.82973 | train_auc: 0.89462 | valid_accuracy: 0.82836 | valid_auc: 0.88565 |  0:08:16s\n",
      "epoch 39 | loss: 0.41951 | train_accuracy: 0.81729 | train_auc: 0.89628 | valid_accuracy: 0.81312 | valid_auc: 0.88561 |  0:08:28s\n",
      "epoch 40 | loss: 0.4167  | train_accuracy: 0.8161  | train_auc: 0.89741 | valid_accuracy: 0.81301 | valid_auc: 0.8859  |  0:08:41s\n",
      "epoch 41 | loss: 0.41889 | train_accuracy: 0.8256  | train_auc: 0.8983  | valid_accuracy: 0.82102 | valid_auc: 0.88584 |  0:08:54s\n",
      "epoch 42 | loss: 0.41333 | train_accuracy: 0.82227 | train_auc: 0.89942 | valid_accuracy: 0.81722 | valid_auc: 0.88561 |  0:09:06s\n",
      "epoch 43 | loss: 0.41424 | train_accuracy: 0.81923 | train_auc: 0.8998  | valid_accuracy: 0.81607 | valid_auc: 0.88579 |  0:09:19s\n",
      "epoch 44 | loss: 0.41327 | train_accuracy: 0.82301 | train_auc: 0.90068 | valid_accuracy: 0.81884 | valid_auc: 0.88562 |  0:09:32s\n",
      "epoch 45 | loss: 0.40592 | train_accuracy: 0.81887 | train_auc: 0.90129 | valid_accuracy: 0.81497 | valid_auc: 0.88578 |  0:09:44s\n",
      "epoch 46 | loss: 0.4085  | train_accuracy: 0.81716 | train_auc: 0.90226 | valid_accuracy: 0.81327 | valid_auc: 0.88528 |  0:09:57s\n",
      "epoch 47 | loss: 0.40648 | train_accuracy: 0.81653 | train_auc: 0.90227 | valid_accuracy: 0.81117 | valid_auc: 0.88565 |  0:10:10s\n",
      "epoch 48 | loss: 0.40571 | train_accuracy: 0.82426 | train_auc: 0.90308 | valid_accuracy: 0.81822 | valid_auc: 0.88432 |  0:10:22s\n",
      "epoch 49 | loss: 0.4056  | train_accuracy: 0.82043 | train_auc: 0.90401 | valid_accuracy: 0.81467 | valid_auc: 0.88447 |  0:10:35s\n",
      "epoch 50 | loss: 0.40185 | train_accuracy: 0.81934 | train_auc: 0.9059  | valid_accuracy: 0.81298 | valid_auc: 0.88398 |  0:10:47s\n",
      "epoch 51 | loss: 0.40089 | train_accuracy: 0.81949 | train_auc: 0.90566 | valid_accuracy: 0.81209 | valid_auc: 0.88502 |  0:11:00s\n",
      "epoch 52 | loss: 0.40079 | train_accuracy: 0.81961 | train_auc: 0.9064  | valid_accuracy: 0.81279 | valid_auc: 0.88465 |  0:11:12s\n",
      "epoch 53 | loss: 0.39851 | train_accuracy: 0.82121 | train_auc: 0.90723 | valid_accuracy: 0.81478 | valid_auc: 0.8843  |  0:11:25s\n",
      "epoch 54 | loss: 0.3956  | train_accuracy: 0.82531 | train_auc: 0.90765 | valid_accuracy: 0.81977 | valid_auc: 0.88349 |  0:11:37s\n",
      "epoch 55 | loss: 0.39423 | train_accuracy: 0.81727 | train_auc: 0.9086  | valid_accuracy: 0.80965 | valid_auc: 0.88369 |  0:11:50s\n",
      "epoch 56 | loss: 0.39663 | train_accuracy: 0.82281 | train_auc: 0.90921 | valid_accuracy: 0.81489 | valid_auc: 0.8839  |  0:12:03s\n",
      "epoch 57 | loss: 0.39482 | train_accuracy: 0.81758 | train_auc: 0.90906 | valid_accuracy: 0.80836 | valid_auc: 0.88334 |  0:12:15s\n",
      "epoch 58 | loss: 0.39318 | train_accuracy: 0.82092 | train_auc: 0.90977 | valid_accuracy: 0.81309 | valid_auc: 0.88465 |  0:12:28s\n",
      "epoch 59 | loss: 0.3937  | train_accuracy: 0.82557 | train_auc: 0.9108  | valid_accuracy: 0.81862 | valid_auc: 0.88383 |  0:12:40s\n",
      "epoch 60 | loss: 0.39045 | train_accuracy: 0.82028 | train_auc: 0.91183 | valid_accuracy: 0.81113 | valid_auc: 0.883   |  0:12:53s\n",
      "epoch 61 | loss: 0.38631 | train_accuracy: 0.82506 | train_auc: 0.91234 | valid_accuracy: 0.81659 | valid_auc: 0.88326 |  0:13:06s\n",
      "epoch 62 | loss: 0.38959 | train_accuracy: 0.82471 | train_auc: 0.91218 | valid_accuracy: 0.81604 | valid_auc: 0.88354 |  0:13:18s\n",
      "epoch 63 | loss: 0.38527 | train_accuracy: 0.82687 | train_auc: 0.91238 | valid_accuracy: 0.81814 | valid_auc: 0.88328 |  0:13:31s\n",
      "epoch 64 | loss: 0.38503 | train_accuracy: 0.82044 | train_auc: 0.91323 | valid_accuracy: 0.81032 | valid_auc: 0.8835  |  0:13:43s\n",
      "epoch 65 | loss: 0.3841  | train_accuracy: 0.8192  | train_auc: 0.91488 | valid_accuracy: 0.80866 | valid_auc: 0.88269 |  0:13:56s\n",
      "epoch 66 | loss: 0.38451 | train_accuracy: 0.82626 | train_auc: 0.91544 | valid_accuracy: 0.81615 | valid_auc: 0.88131 |  0:14:08s\n",
      "epoch 67 | loss: 0.3845  | train_accuracy: 0.82279 | train_auc: 0.91531 | valid_accuracy: 0.8129  | valid_auc: 0.88138 |  0:14:21s\n",
      "epoch 68 | loss: 0.38072 | train_accuracy: 0.82622 | train_auc: 0.91604 | valid_accuracy: 0.81737 | valid_auc: 0.88059 |  0:14:33s\n",
      "epoch 69 | loss: 0.38073 | train_accuracy: 0.82591 | train_auc: 0.91636 | valid_accuracy: 0.81604 | valid_auc: 0.88185 |  0:14:46s\n",
      "epoch 70 | loss: 0.37856 | train_accuracy: 0.835   | train_auc: 0.91633 | valid_accuracy: 0.82574 | valid_auc: 0.88044 |  0:14:57s\n",
      "epoch 71 | loss: 0.3777  | train_accuracy: 0.82015 | train_auc: 0.91765 | valid_accuracy: 0.80906 | valid_auc: 0.87954 |  0:15:10s\n",
      "epoch 72 | loss: 0.37896 | train_accuracy: 0.8219  | train_auc: 0.91811 | valid_accuracy: 0.81124 | valid_auc: 0.88012 |  0:15:22s\n",
      "epoch 73 | loss: 0.37363 | train_accuracy: 0.82597 | train_auc: 0.91802 | valid_accuracy: 0.81523 | valid_auc: 0.88028 |  0:15:35s\n",
      "epoch 74 | loss: 0.37361 | train_accuracy: 0.82891 | train_auc: 0.91897 | valid_accuracy: 0.81814 | valid_auc: 0.87909 |  0:15:48s\n",
      "epoch 75 | loss: 0.37693 | train_accuracy: 0.82985 | train_auc: 0.919   | valid_accuracy: 0.81755 | valid_auc: 0.87958 |  0:16:00s\n",
      "epoch 76 | loss: 0.37285 | train_accuracy: 0.8334  | train_auc: 0.91977 | valid_accuracy: 0.82165 | valid_auc: 0.87949 |  0:16:13s\n",
      "epoch 77 | loss: 0.37023 | train_accuracy: 0.82437 | train_auc: 0.92015 | valid_accuracy: 0.81209 | valid_auc: 0.87905 |  0:16:25s\n",
      "epoch 78 | loss: 0.37486 | train_accuracy: 0.82402 | train_auc: 0.9203  | valid_accuracy: 0.81194 | valid_auc: 0.87916 |  0:16:38s\n",
      "epoch 79 | loss: 0.36992 | train_accuracy: 0.8307  | train_auc: 0.92153 | valid_accuracy: 0.81781 | valid_auc: 0.8789  |  0:16:50s\n",
      "epoch 80 | loss: 0.36957 | train_accuracy: 0.82719 | train_auc: 0.92149 | valid_accuracy: 0.81482 | valid_auc: 0.879   |  0:17:03s\n",
      "epoch 81 | loss: 0.37281 | train_accuracy: 0.83394 | train_auc: 0.92157 | valid_accuracy: 0.82146 | valid_auc: 0.8777  |  0:17:15s\n",
      "epoch 82 | loss: 0.37058 | train_accuracy: 0.81921 | train_auc: 0.92207 | valid_accuracy: 0.80585 | valid_auc: 0.87793 |  0:17:28s\n",
      "epoch 83 | loss: 0.36947 | train_accuracy: 0.82269 | train_auc: 0.92285 | valid_accuracy: 0.80825 | valid_auc: 0.87751 |  0:17:40s\n",
      "epoch 84 | loss: 0.36842 | train_accuracy: 0.82916 | train_auc: 0.92251 | valid_accuracy: 0.81519 | valid_auc: 0.87775 |  0:17:53s\n",
      "epoch 85 | loss: 0.36904 | train_accuracy: 0.8245  | train_auc: 0.92306 | valid_accuracy: 0.81069 | valid_auc: 0.87718 |  0:18:05s\n",
      "epoch 86 | loss: 0.36628 | train_accuracy: 0.82867 | train_auc: 0.92325 | valid_accuracy: 0.81578 | valid_auc: 0.87797 |  0:18:18s\n",
      "epoch 87 | loss: 0.36682 | train_accuracy: 0.82569 | train_auc: 0.92327 | valid_accuracy: 0.81039 | valid_auc: 0.87702 |  0:18:31s\n",
      "epoch 88 | loss: 0.36418 | train_accuracy: 0.82703 | train_auc: 0.92363 | valid_accuracy: 0.81205 | valid_auc: 0.8765  |  0:18:43s\n",
      "epoch 89 | loss: 0.36408 | train_accuracy: 0.82163 | train_auc: 0.92466 | valid_accuracy: 0.80737 | valid_auc: 0.87733 |  0:18:56s\n",
      "epoch 90 | loss: 0.36045 | train_accuracy: 0.82126 | train_auc: 0.92544 | valid_accuracy: 0.80545 | valid_auc: 0.8766  |  0:19:09s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 40 and best_valid_auc = 0.8859\n"
     ]
    }
   ],
   "source": [
    "clf2_preproc.fit(\n",
    "    train_features.values, train_labels, \\\n",
    "    eval_set=[(train_features.values, train_labels), (val_features.values, val_labels)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy','auc'],\n",
    "    max_epochs=1000 , patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=loaded_pretrain\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T15:35:35.018635Z",
     "iopub.status.busy": "2023-12-17T15:35:35.018282Z",
     "iopub.status.idle": "2023-12-17T17:24:51.696637Z",
     "shell.execute_reply": "2023-12-17T17:24:51.696016Z",
     "shell.execute_reply.started": "2023-12-17T15:35:35.018611Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76007 | train_accuracy: 0.60151 | train_auc: 0.62778 | valid_accuracy: 0.60104 | valid_auc: 0.62084 |  0:00:16s\n",
      "epoch 1  | loss: 0.70474 | train_accuracy: 0.66476 | train_auc: 0.74454 | valid_accuracy: 0.66448 | valid_auc: 0.75258 |  0:00:31s\n",
      "epoch 2  | loss: 0.65375 | train_accuracy: 0.73641 | train_auc: 0.77078 | valid_accuracy: 0.73729 | valid_auc: 0.78115 |  0:00:47s\n",
      "epoch 3  | loss: 0.61356 | train_accuracy: 0.77518 | train_auc: 0.80067 | valid_accuracy: 0.77633 | valid_auc: 0.80815 |  0:01:02s\n",
      "epoch 4  | loss: 0.58724 | train_accuracy: 0.77423 | train_auc: 0.80556 | valid_accuracy: 0.77463 | valid_auc: 0.81103 |  0:01:17s\n",
      "epoch 5  | loss: 0.57014 | train_accuracy: 0.77684 | train_auc: 0.81085 | valid_accuracy: 0.77847 | valid_auc: 0.81557 |  0:01:32s\n",
      "epoch 6  | loss: 0.55908 | train_accuracy: 0.7844  | train_auc: 0.81458 | valid_accuracy: 0.78703 | valid_auc: 0.82131 |  0:01:48s\n",
      "epoch 7  | loss: 0.55115 | train_accuracy: 0.76726 | train_auc: 0.81784 | valid_accuracy: 0.76803 | valid_auc: 0.82335 |  0:02:04s\n",
      "epoch 8  | loss: 0.5414  | train_accuracy: 0.7697  | train_auc: 0.82101 | valid_accuracy: 0.77013 | valid_auc: 0.82756 |  0:02:20s\n",
      "epoch 9  | loss: 0.53568 | train_accuracy: 0.77614 | train_auc: 0.82362 | valid_accuracy: 0.77825 | valid_auc: 0.83164 |  0:02:36s\n",
      "epoch 10 | loss: 0.52768 | train_accuracy: 0.78534 | train_auc: 0.83213 | valid_accuracy: 0.78766 | valid_auc: 0.83729 |  0:02:50s\n",
      "epoch 11 | loss: 0.51601 | train_accuracy: 0.78493 | train_auc: 0.83835 | valid_accuracy: 0.78618 | valid_auc: 0.84349 |  0:03:05s\n",
      "epoch 12 | loss: 0.51143 | train_accuracy: 0.78576 | train_auc: 0.84399 | valid_accuracy: 0.78788 | valid_auc: 0.85007 |  0:03:19s\n",
      "epoch 13 | loss: 0.504   | train_accuracy: 0.77449 | train_auc: 0.84727 | valid_accuracy: 0.77781 | valid_auc: 0.85493 |  0:03:33s\n",
      "epoch 14 | loss: 0.49685 | train_accuracy: 0.77521 | train_auc: 0.85063 | valid_accuracy: 0.77862 | valid_auc: 0.85902 |  0:03:48s\n",
      "epoch 15 | loss: 0.49148 | train_accuracy: 0.78636 | train_auc: 0.85586 | valid_accuracy: 0.7898  | valid_auc: 0.86428 |  0:04:03s\n",
      "epoch 16 | loss: 0.48327 | train_accuracy: 0.78469 | train_auc: 0.85748 | valid_accuracy: 0.78818 | valid_auc: 0.86518 |  0:04:19s\n",
      "epoch 17 | loss: 0.48252 | train_accuracy: 0.79078 | train_auc: 0.86057 | valid_accuracy: 0.79297 | valid_auc: 0.86829 |  0:04:34s\n",
      "epoch 18 | loss: 0.4761  | train_accuracy: 0.79766 | train_auc: 0.86352 | valid_accuracy: 0.79903 | valid_auc: 0.87035 |  0:04:50s\n",
      "epoch 19 | loss: 0.47278 | train_accuracy: 0.79239 | train_auc: 0.86503 | valid_accuracy: 0.7926  | valid_auc: 0.87155 |  0:05:04s\n",
      "epoch 20 | loss: 0.46622 | train_accuracy: 0.80066 | train_auc: 0.86682 | valid_accuracy: 0.80054 | valid_auc: 0.87332 |  0:05:19s\n",
      "epoch 21 | loss: 0.46569 | train_accuracy: 0.80619 | train_auc: 0.86846 | valid_accuracy: 0.806   | valid_auc: 0.87435 |  0:05:33s\n",
      "epoch 22 | loss: 0.46375 | train_accuracy: 0.80025 | train_auc: 0.87039 | valid_accuracy: 0.80109 | valid_auc: 0.8757  |  0:05:48s\n",
      "epoch 23 | loss: 0.4597  | train_accuracy: 0.79701 | train_auc: 0.87091 | valid_accuracy: 0.79814 | valid_auc: 0.87654 |  0:06:02s\n",
      "epoch 24 | loss: 0.45812 | train_accuracy: 0.79505 | train_auc: 0.87268 | valid_accuracy: 0.79685 | valid_auc: 0.87762 |  0:06:16s\n",
      "epoch 25 | loss: 0.45445 | train_accuracy: 0.80823 | train_auc: 0.87351 | valid_accuracy: 0.80814 | valid_auc: 0.87834 |  0:06:30s\n",
      "epoch 26 | loss: 0.45316 | train_accuracy: 0.8087  | train_auc: 0.87561 | valid_accuracy: 0.80862 | valid_auc: 0.87997 |  0:06:45s\n",
      "epoch 27 | loss: 0.45198 | train_accuracy: 0.80746 | train_auc: 0.87697 | valid_accuracy: 0.80847 | valid_auc: 0.88105 |  0:06:59s\n",
      "epoch 28 | loss: 0.45151 | train_accuracy: 0.80808 | train_auc: 0.8778  | valid_accuracy: 0.8084  | valid_auc: 0.88102 |  0:14:43s\n",
      "epoch 29 | loss: 0.44587 | train_accuracy: 0.80991 | train_auc: 0.87969 | valid_accuracy: 0.80969 | valid_auc: 0.88065 |  0:16:04s\n",
      "epoch 30 | loss: 0.44388 | train_accuracy: 0.8127  | train_auc: 0.88118 | valid_accuracy: 0.81283 | valid_auc: 0.88221 |  0:36:45s\n",
      "epoch 31 | loss: 0.44264 | train_accuracy: 0.81621 | train_auc: 0.88262 | valid_accuracy: 0.81504 | valid_auc: 0.88207 |  1:13:57s\n",
      "epoch 32 | loss: 0.44293 | train_accuracy: 0.81119 | train_auc: 0.88258 | valid_accuracy: 0.81058 | valid_auc: 0.88325 |  1:34:55s\n",
      "epoch 33 | loss: 0.43651 | train_accuracy: 0.80934 | train_auc: 0.88328 | valid_accuracy: 0.80855 | valid_auc: 0.88211 |  1:35:11s\n",
      "epoch 34 | loss: 0.43438 | train_accuracy: 0.80684 | train_auc: 0.88521 | valid_accuracy: 0.80493 | valid_auc: 0.88382 |  1:35:25s\n",
      "epoch 35 | loss: 0.43346 | train_accuracy: 0.81266 | train_auc: 0.88623 | valid_accuracy: 0.81095 | valid_auc: 0.88368 |  1:35:40s\n",
      "epoch 36 | loss: 0.43365 | train_accuracy: 0.81491 | train_auc: 0.88641 | valid_accuracy: 0.81312 | valid_auc: 0.88332 |  1:35:54s\n",
      "epoch 37 | loss: 0.43255 | train_accuracy: 0.81142 | train_auc: 0.88742 | valid_accuracy: 0.81002 | valid_auc: 0.88381 |  1:36:08s\n",
      "epoch 38 | loss: 0.42986 | train_accuracy: 0.81853 | train_auc: 0.88825 | valid_accuracy: 0.81667 | valid_auc: 0.88357 |  1:36:23s\n",
      "epoch 39 | loss: 0.42856 | train_accuracy: 0.80618 | train_auc: 0.88972 | valid_accuracy: 0.80408 | valid_auc: 0.88386 |  1:36:37s\n",
      "epoch 40 | loss: 0.42583 | train_accuracy: 0.81366 | train_auc: 0.89049 | valid_accuracy: 0.81216 | valid_auc: 0.8842  |  1:36:53s\n",
      "epoch 41 | loss: 0.42802 | train_accuracy: 0.81519 | train_auc: 0.89177 | valid_accuracy: 0.81286 | valid_auc: 0.88385 |  1:37:09s\n",
      "epoch 42 | loss: 0.42636 | train_accuracy: 0.81179 | train_auc: 0.89142 | valid_accuracy: 0.80895 | valid_auc: 0.88348 |  1:37:24s\n",
      "epoch 43 | loss: 0.42243 | train_accuracy: 0.81541 | train_auc: 0.8937  | valid_accuracy: 0.81202 | valid_auc: 0.88389 |  1:37:39s\n",
      "epoch 44 | loss: 0.42319 | train_accuracy: 0.81645 | train_auc: 0.89362 | valid_accuracy: 0.81327 | valid_auc: 0.88382 |  1:37:53s\n",
      "epoch 45 | loss: 0.41554 | train_accuracy: 0.80912 | train_auc: 0.89489 | valid_accuracy: 0.80486 | valid_auc: 0.88382 |  1:38:07s\n",
      "epoch 46 | loss: 0.41942 | train_accuracy: 0.81186 | train_auc: 0.89625 | valid_accuracy: 0.80692 | valid_auc: 0.88389 |  1:38:21s\n",
      "epoch 47 | loss: 0.41723 | train_accuracy: 0.81353 | train_auc: 0.89573 | valid_accuracy: 0.80969 | valid_auc: 0.88402 |  1:38:36s\n",
      "epoch 48 | loss: 0.4161  | train_accuracy: 0.81377 | train_auc: 0.89678 | valid_accuracy: 0.80973 | valid_auc: 0.88393 |  1:38:50s\n",
      "epoch 49 | loss: 0.41626 | train_accuracy: 0.80752 | train_auc: 0.89794 | valid_accuracy: 0.80323 | valid_auc: 0.88321 |  1:39:04s\n",
      "epoch 50 | loss: 0.41235 | train_accuracy: 0.80392 | train_auc: 0.8993  | valid_accuracy: 0.79792 | valid_auc: 0.88266 |  1:39:19s\n",
      "epoch 51 | loss: 0.40877 | train_accuracy: 0.81103 | train_auc: 0.89992 | valid_accuracy: 0.80593 | valid_auc: 0.88282 |  1:39:33s\n",
      "epoch 52 | loss: 0.4103  | train_accuracy: 0.81287 | train_auc: 0.90067 | valid_accuracy: 0.80678 | valid_auc: 0.88299 |  1:39:48s\n",
      "epoch 53 | loss: 0.40727 | train_accuracy: 0.80882 | train_auc: 0.90192 | valid_accuracy: 0.80216 | valid_auc: 0.88225 |  1:40:02s\n",
      "epoch 54 | loss: 0.40514 | train_accuracy: 0.80769 | train_auc: 0.90189 | valid_accuracy: 0.80002 | valid_auc: 0.88144 |  1:40:17s\n",
      "epoch 55 | loss: 0.40334 | train_accuracy: 0.80878 | train_auc: 0.90288 | valid_accuracy: 0.80102 | valid_auc: 0.88307 |  1:40:31s\n",
      "epoch 56 | loss: 0.40588 | train_accuracy: 0.81841 | train_auc: 0.90318 | valid_accuracy: 0.81161 | valid_auc: 0.88373 |  1:40:46s\n",
      "epoch 57 | loss: 0.40316 | train_accuracy: 0.80161 | train_auc: 0.90378 | valid_accuracy: 0.7936  | valid_auc: 0.88145 |  1:41:00s\n",
      "epoch 58 | loss: 0.40245 | train_accuracy: 0.80575 | train_auc: 0.90543 | valid_accuracy: 0.79777 | valid_auc: 0.88096 |  1:41:15s\n",
      "epoch 59 | loss: 0.40175 | train_accuracy: 0.80871 | train_auc: 0.9065  | valid_accuracy: 0.80072 | valid_auc: 0.88147 |  1:41:31s\n",
      "epoch 60 | loss: 0.39995 | train_accuracy: 0.79869 | train_auc: 0.90725 | valid_accuracy: 0.78947 | valid_auc: 0.88039 |  1:41:46s\n",
      "epoch 61 | loss: 0.39502 | train_accuracy: 0.80807 | train_auc: 0.90774 | valid_accuracy: 0.79991 | valid_auc: 0.88144 |  1:42:00s\n",
      "epoch 62 | loss: 0.39522 | train_accuracy: 0.8055  | train_auc: 0.90766 | valid_accuracy: 0.79781 | valid_auc: 0.8818  |  1:42:14s\n",
      "epoch 63 | loss: 0.39232 | train_accuracy: 0.81389 | train_auc: 0.90877 | valid_accuracy: 0.80681 | valid_auc: 0.88187 |  1:42:29s\n",
      "epoch 64 | loss: 0.39295 | train_accuracy: 0.80836 | train_auc: 0.90934 | valid_accuracy: 0.80168 | valid_auc: 0.88121 |  1:42:43s\n",
      "epoch 65 | loss: 0.39046 | train_accuracy: 0.81141 | train_auc: 0.91119 | valid_accuracy: 0.80364 | valid_auc: 0.8809  |  1:42:58s\n",
      "epoch 66 | loss: 0.3896  | train_accuracy: 0.81224 | train_auc: 0.91188 | valid_accuracy: 0.8046  | valid_auc: 0.88006 |  1:43:12s\n",
      "epoch 67 | loss: 0.38938 | train_accuracy: 0.80909 | train_auc: 0.91216 | valid_accuracy: 0.80157 | valid_auc: 0.87959 |  1:43:26s\n",
      "epoch 68 | loss: 0.3877  | train_accuracy: 0.81105 | train_auc: 0.91254 | valid_accuracy: 0.80268 | valid_auc: 0.87873 |  1:43:41s\n",
      "epoch 69 | loss: 0.38623 | train_accuracy: 0.81017 | train_auc: 0.91287 | valid_accuracy: 0.80213 | valid_auc: 0.87865 |  1:43:55s\n",
      "epoch 70 | loss: 0.38469 | train_accuracy: 0.81231 | train_auc: 0.91359 | valid_accuracy: 0.8063  | valid_auc: 0.87935 |  1:44:10s\n",
      "epoch 71 | loss: 0.38163 | train_accuracy: 0.80757 | train_auc: 0.91444 | valid_accuracy: 0.7988  | valid_auc: 0.87866 |  1:44:24s\n",
      "epoch 72 | loss: 0.38339 | train_accuracy: 0.80059 | train_auc: 0.91509 | valid_accuracy: 0.79301 | valid_auc: 0.87839 |  1:44:38s\n",
      "epoch 73 | loss: 0.37953 | train_accuracy: 0.81467 | train_auc: 0.91555 | valid_accuracy: 0.80729 | valid_auc: 0.87864 |  1:44:53s\n",
      "epoch 74 | loss: 0.3798  | train_accuracy: 0.81729 | train_auc: 0.91654 | valid_accuracy: 0.81013 | valid_auc: 0.87896 |  1:45:07s\n",
      "epoch 75 | loss: 0.38    | train_accuracy: 0.81098 | train_auc: 0.91705 | valid_accuracy: 0.80106 | valid_auc: 0.87754 |  1:45:22s\n",
      "epoch 76 | loss: 0.37636 | train_accuracy: 0.81802 | train_auc: 0.91739 | valid_accuracy: 0.80833 | valid_auc: 0.8784  |  1:45:36s\n",
      "epoch 77 | loss: 0.37312 | train_accuracy: 0.81431 | train_auc: 0.91774 | valid_accuracy: 0.80379 | valid_auc: 0.87711 |  1:45:50s\n",
      "epoch 78 | loss: 0.37755 | train_accuracy: 0.81261 | train_auc: 0.91888 | valid_accuracy: 0.80224 | valid_auc: 0.87607 |  1:46:06s\n",
      "epoch 79 | loss: 0.37327 | train_accuracy: 0.81693 | train_auc: 0.91954 | valid_accuracy: 0.80692 | valid_auc: 0.876   |  1:46:20s\n",
      "epoch 80 | loss: 0.37132 | train_accuracy: 0.81745 | train_auc: 0.92021 | valid_accuracy: 0.80755 | valid_auc: 0.87559 |  1:46:35s\n",
      "epoch 81 | loss: 0.37489 | train_accuracy: 0.81563 | train_auc: 0.92017 | valid_accuracy: 0.80585 | valid_auc: 0.87476 |  1:46:49s\n",
      "epoch 82 | loss: 0.37343 | train_accuracy: 0.81091 | train_auc: 0.92093 | valid_accuracy: 0.80098 | valid_auc: 0.87562 |  1:47:03s\n",
      "epoch 83 | loss: 0.37069 | train_accuracy: 0.80207 | train_auc: 0.92154 | valid_accuracy: 0.79201 | valid_auc: 0.87402 |  1:47:18s\n",
      "epoch 84 | loss: 0.37131 | train_accuracy: 0.81393 | train_auc: 0.92219 | valid_accuracy: 0.80327 | valid_auc: 0.87411 |  1:47:32s\n",
      "epoch 85 | loss: 0.36694 | train_accuracy: 0.81593 | train_auc: 0.9221  | valid_accuracy: 0.80548 | valid_auc: 0.87505 |  1:47:46s\n",
      "epoch 86 | loss: 0.36565 | train_accuracy: 0.81247 | train_auc: 0.922   | valid_accuracy: 0.80249 | valid_auc: 0.87347 |  1:48:01s\n",
      "epoch 87 | loss: 0.36665 | train_accuracy: 0.81159 | train_auc: 0.92246 | valid_accuracy: 0.80076 | valid_auc: 0.87339 |  1:48:15s\n",
      "epoch 88 | loss: 0.36572 | train_accuracy: 0.8115  | train_auc: 0.92314 | valid_accuracy: 0.80091 | valid_auc: 0.87379 |  1:48:30s\n",
      "epoch 89 | loss: 0.3616  | train_accuracy: 0.80903 | train_auc: 0.9241  | valid_accuracy: 0.79762 | valid_auc: 0.87238 |  1:48:44s\n",
      "epoch 90 | loss: 0.36241 | train_accuracy: 0.81281 | train_auc: 0.92414 | valid_accuracy: 0.80087 | valid_auc: 0.87189 |  1:48:59s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 40 and best_valid_auc = 0.8842\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "clf1_nopreproc = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type= 'entmax' #\"sparsemax\"\n",
    "                      )\n",
    "\n",
    "# fit the model \n",
    "clf1_nopreproc.fit(\n",
    "    train_features.values, train_labels, \\\n",
    "    eval_set=[(train_features.values, train_labels), (val_features.values, val_labels)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy','auc'],\n",
    "    max_epochs=1000 , patience=50,\n",
    "    batch_size=1024, virtual_batch_size=256,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T17:26:15.194731Z",
     "iopub.status.busy": "2023-12-17T17:26:15.194078Z",
     "iopub.status.idle": "2023-12-17T20:13:05.608284Z",
     "shell.execute_reply": "2023-12-17T20:13:05.607626Z",
     "shell.execute_reply.started": "2023-12-17T17:26:15.194679Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71458 | train_accuracy: 0.78669 | train_auc: 0.77344 | valid_accuracy: 0.7857  | valid_auc: 0.78314 |  0:00:31s\n",
      "epoch 1  | loss: 0.622   | train_accuracy: 0.80857 | train_auc: 0.79493 | valid_accuracy: 0.80781 | valid_auc: 0.8001  |  0:01:02s\n",
      "epoch 2  | loss: 0.58627 | train_accuracy: 0.79502 | train_auc: 0.80505 | valid_accuracy: 0.79644 | valid_auc: 0.81088 |  0:01:33s\n",
      "epoch 3  | loss: 0.56348 | train_accuracy: 0.78316 | train_auc: 0.8157  | valid_accuracy: 0.78519 | valid_auc: 0.82266 |  0:02:04s\n",
      "epoch 4  | loss: 0.54082 | train_accuracy: 0.79806 | train_auc: 0.82765 | valid_accuracy: 0.79818 | valid_auc: 0.83841 |  0:02:35s\n",
      "epoch 5  | loss: 0.5268  | train_accuracy: 0.80553 | train_auc: 0.84107 | valid_accuracy: 0.80711 | valid_auc: 0.84757 |  0:03:06s\n",
      "epoch 6  | loss: 0.50757 | train_accuracy: 0.80606 | train_auc: 0.84692 | valid_accuracy: 0.80655 | valid_auc: 0.85255 |  0:03:37s\n",
      "epoch 7  | loss: 0.50008 | train_accuracy: 0.7979  | train_auc: 0.85191 | valid_accuracy: 0.7984  | valid_auc: 0.85608 |  0:04:08s\n",
      "epoch 8  | loss: 0.48769 | train_accuracy: 0.80843 | train_auc: 0.85708 | valid_accuracy: 0.80892 | valid_auc: 0.8635  |  0:04:39s\n",
      "epoch 9  | loss: 0.48242 | train_accuracy: 0.81788 | train_auc: 0.86219 | valid_accuracy: 0.81818 | valid_auc: 0.86959 |  0:05:10s\n",
      "epoch 10 | loss: 0.47532 | train_accuracy: 0.8043  | train_auc: 0.86423 | valid_accuracy: 0.80445 | valid_auc: 0.86899 |  0:05:41s\n",
      "epoch 11 | loss: 0.46617 | train_accuracy: 0.80615 | train_auc: 0.86831 | valid_accuracy: 0.8063  | valid_auc: 0.87335 |  0:06:12s\n",
      "epoch 12 | loss: 0.46407 | train_accuracy: 0.81269 | train_auc: 0.87114 | valid_accuracy: 0.81161 | valid_auc: 0.87387 |  0:07:18s\n",
      "epoch 13 | loss: 0.45996 | train_accuracy: 0.80217 | train_auc: 0.87339 | valid_accuracy: 0.80246 | valid_auc: 0.87637 |  0:07:49s\n",
      "epoch 14 | loss: 0.45245 | train_accuracy: 0.8183  | train_auc: 0.87569 | valid_accuracy: 0.81932 | valid_auc: 0.87746 |  0:08:20s\n",
      "epoch 15 | loss: 0.45064 | train_accuracy: 0.81782 | train_auc: 0.87774 | valid_accuracy: 0.81829 | valid_auc: 0.87818 |  0:08:51s\n",
      "epoch 16 | loss: 0.4482  | train_accuracy: 0.81317 | train_auc: 0.88072 | valid_accuracy: 0.81327 | valid_auc: 0.88002 |  0:09:22s\n",
      "epoch 17 | loss: 0.44565 | train_accuracy: 0.82393 | train_auc: 0.88278 | valid_accuracy: 0.82397 | valid_auc: 0.88186 |  0:09:53s\n",
      "epoch 18 | loss: 0.43999 | train_accuracy: 0.81579 | train_auc: 0.88347 | valid_accuracy: 0.81548 | valid_auc: 0.88132 |  0:10:25s\n",
      "epoch 19 | loss: 0.43755 | train_accuracy: 0.8099  | train_auc: 0.8857  | valid_accuracy: 0.80991 | valid_auc: 0.88346 |  0:10:56s\n",
      "epoch 20 | loss: 0.43262 | train_accuracy: 0.8186  | train_auc: 0.88752 | valid_accuracy: 0.81807 | valid_auc: 0.8842  |  0:11:27s\n",
      "epoch 21 | loss: 0.43116 | train_accuracy: 0.81409 | train_auc: 0.88805 | valid_accuracy: 0.81264 | valid_auc: 0.88444 |  0:11:58s\n",
      "epoch 22 | loss: 0.42872 | train_accuracy: 0.80821 | train_auc: 0.89043 | valid_accuracy: 0.80674 | valid_auc: 0.88444 |  0:12:30s\n",
      "epoch 23 | loss: 0.42507 | train_accuracy: 0.8082  | train_auc: 0.89158 | valid_accuracy: 0.80726 | valid_auc: 0.88669 |  0:13:01s\n",
      "epoch 24 | loss: 0.42326 | train_accuracy: 0.81414 | train_auc: 0.89244 | valid_accuracy: 0.81272 | valid_auc: 0.88575 |  0:13:32s\n",
      "epoch 25 | loss: 0.42112 | train_accuracy: 0.80071 | train_auc: 0.89357 | valid_accuracy: 0.79796 | valid_auc: 0.88588 |  0:14:03s\n",
      "epoch 26 | loss: 0.41677 | train_accuracy: 0.81417 | train_auc: 0.89569 | valid_accuracy: 0.81172 | valid_auc: 0.88661 |  0:14:34s\n",
      "epoch 27 | loss: 0.41841 | train_accuracy: 0.82627 | train_auc: 0.89699 | valid_accuracy: 0.82405 | valid_auc: 0.88643 |  0:15:05s\n",
      "epoch 28 | loss: 0.41693 | train_accuracy: 0.82652 | train_auc: 0.89959 | valid_accuracy: 0.82368 | valid_auc: 0.88593 |  0:15:36s\n",
      "epoch 29 | loss: 0.41267 | train_accuracy: 0.80722 | train_auc: 0.89988 | valid_accuracy: 0.80194 | valid_auc: 0.88667 |  0:16:07s\n",
      "epoch 30 | loss: 0.40887 | train_accuracy: 0.82004 | train_auc: 0.90169 | valid_accuracy: 0.81611 | valid_auc: 0.88629 |  0:16:38s\n",
      "epoch 31 | loss: 0.40698 | train_accuracy: 0.82074 | train_auc: 0.90234 | valid_accuracy: 0.8156  | valid_auc: 0.88463 |  0:17:09s\n",
      "epoch 32 | loss: 0.40756 | train_accuracy: 0.8144  | train_auc: 0.90297 | valid_accuracy: 0.81095 | valid_auc: 0.88694 |  0:17:40s\n",
      "epoch 33 | loss: 0.40117 | train_accuracy: 0.82473 | train_auc: 0.90546 | valid_accuracy: 0.82113 | valid_auc: 0.88681 |  0:18:11s\n",
      "epoch 34 | loss: 0.39709 | train_accuracy: 0.82683 | train_auc: 0.90577 | valid_accuracy: 0.82235 | valid_auc: 0.88683 |  0:18:43s\n",
      "epoch 35 | loss: 0.39655 | train_accuracy: 0.81165 | train_auc: 0.90698 | valid_accuracy: 0.80659 | valid_auc: 0.88506 |  0:19:14s\n",
      "epoch 36 | loss: 0.3981  | train_accuracy: 0.81114 | train_auc: 0.90596 | valid_accuracy: 0.80604 | valid_auc: 0.88536 |  0:19:45s\n",
      "epoch 37 | loss: 0.39467 | train_accuracy: 0.81041 | train_auc: 0.90871 | valid_accuracy: 0.80585 | valid_auc: 0.88623 |  0:20:16s\n",
      "epoch 38 | loss: 0.39305 | train_accuracy: 0.82256 | train_auc: 0.90932 | valid_accuracy: 0.81814 | valid_auc: 0.88507 |  0:20:47s\n",
      "epoch 39 | loss: 0.39145 | train_accuracy: 0.82683 | train_auc: 0.91154 | valid_accuracy: 0.82179 | valid_auc: 0.8866  |  0:21:18s\n",
      "epoch 40 | loss: 0.3884  | train_accuracy: 0.80964 | train_auc: 0.91283 | valid_accuracy: 0.80464 | valid_auc: 0.88685 |  0:21:49s\n",
      "epoch 41 | loss: 0.38996 | train_accuracy: 0.82783 | train_auc: 0.91278 | valid_accuracy: 0.82419 | valid_auc: 0.88702 |  0:22:20s\n",
      "epoch 42 | loss: 0.38627 | train_accuracy: 0.80993 | train_auc: 0.91399 | valid_accuracy: 0.80238 | valid_auc: 0.88541 |  0:22:52s\n",
      "epoch 43 | loss: 0.38502 | train_accuracy: 0.81053 | train_auc: 0.91424 | valid_accuracy: 0.8053  | valid_auc: 0.88543 |  0:23:23s\n",
      "epoch 44 | loss: 0.38465 | train_accuracy: 0.80578 | train_auc: 0.91593 | valid_accuracy: 0.79892 | valid_auc: 0.8839  |  0:23:54s\n",
      "epoch 45 | loss: 0.37867 | train_accuracy: 0.8206  | train_auc: 0.91636 | valid_accuracy: 0.81471 | valid_auc: 0.88595 |  0:24:25s\n",
      "epoch 46 | loss: 0.38102 | train_accuracy: 0.81775 | train_auc: 0.91628 | valid_accuracy: 0.8101  | valid_auc: 0.88461 |  0:24:56s\n",
      "epoch 47 | loss: 0.37819 | train_accuracy: 0.80296 | train_auc: 0.9161  | valid_accuracy: 0.79847 | valid_auc: 0.88197 |  0:25:27s\n",
      "epoch 48 | loss: 0.37821 | train_accuracy: 0.80976 | train_auc: 0.9183  | valid_accuracy: 0.80397 | valid_auc: 0.88547 |  0:25:58s\n",
      "epoch 49 | loss: 0.37715 | train_accuracy: 0.80635 | train_auc: 0.91974 | valid_accuracy: 0.79954 | valid_auc: 0.88277 |  0:29:50s\n",
      "epoch 50 | loss: 0.37402 | train_accuracy: 0.80959 | train_auc: 0.91999 | valid_accuracy: 0.80279 | valid_auc: 0.88322 |  0:30:21s\n",
      "epoch 51 | loss: 0.36966 | train_accuracy: 0.8146  | train_auc: 0.92072 | valid_accuracy: 0.80836 | valid_auc: 0.88267 |  0:30:52s\n",
      "epoch 52 | loss: 0.37105 | train_accuracy: 0.80625 | train_auc: 0.91974 | valid_accuracy: 0.79906 | valid_auc: 0.88102 |  0:31:23s\n",
      "epoch 53 | loss: 0.37017 | train_accuracy: 0.80601 | train_auc: 0.92107 | valid_accuracy: 0.79796 | valid_auc: 0.88228 |  0:31:54s\n",
      "epoch 54 | loss: 0.36807 | train_accuracy: 0.81005 | train_auc: 0.92189 | valid_accuracy: 0.80109 | valid_auc: 0.88009 |  0:32:25s\n",
      "epoch 55 | loss: 0.36492 | train_accuracy: 0.8233  | train_auc: 0.92401 | valid_accuracy: 0.81626 | valid_auc: 0.88243 |  0:32:56s\n",
      "epoch 56 | loss: 0.36758 | train_accuracy: 0.81438 | train_auc: 0.92191 | valid_accuracy: 0.80618 | valid_auc: 0.87962 |  0:33:27s\n",
      "epoch 57 | loss: 0.36535 | train_accuracy: 0.81685 | train_auc: 0.92307 | valid_accuracy: 0.80906 | valid_auc: 0.88168 |  0:33:58s\n",
      "epoch 58 | loss: 0.36317 | train_accuracy: 0.80638 | train_auc: 0.92394 | valid_accuracy: 0.79729 | valid_auc: 0.88213 |  0:34:29s\n",
      "epoch 59 | loss: 0.36374 | train_accuracy: 0.81564 | train_auc: 0.92536 | valid_accuracy: 0.8063  | valid_auc: 0.88064 |  0:35:00s\n",
      "epoch 60 | loss: 0.36388 | train_accuracy: 0.80609 | train_auc: 0.92539 | valid_accuracy: 0.79681 | valid_auc: 0.88026 |  0:35:31s\n",
      "epoch 61 | loss: 0.35737 | train_accuracy: 0.81272 | train_auc: 0.92648 | valid_accuracy: 0.80404 | valid_auc: 0.87973 |  0:36:02s\n",
      "epoch 62 | loss: 0.36114 | train_accuracy: 0.80636 | train_auc: 0.92606 | valid_accuracy: 0.79641 | valid_auc: 0.88208 |  0:36:34s\n",
      "epoch 63 | loss: 0.35506 | train_accuracy: 0.828   | train_auc: 0.9271  | valid_accuracy: 0.81877 | valid_auc: 0.88021 |  0:37:05s\n",
      "epoch 64 | loss: 0.35602 | train_accuracy: 0.81581 | train_auc: 0.92653 | valid_accuracy: 0.805   | valid_auc: 0.87977 |  0:37:36s\n",
      "epoch 65 | loss: 0.35636 | train_accuracy: 0.80509 | train_auc: 0.9276  | valid_accuracy: 0.79497 | valid_auc: 0.88009 |  0:44:41s\n",
      "epoch 66 | loss: 0.35427 | train_accuracy: 0.81489 | train_auc: 0.92852 | valid_accuracy: 0.80297 | valid_auc: 0.87695 |  2:12:23s\n",
      "epoch 67 | loss: 0.35726 | train_accuracy: 0.81429 | train_auc: 0.92836 | valid_accuracy: 0.80382 | valid_auc: 0.87697 |  2:12:54s\n",
      "epoch 68 | loss: 0.3528  | train_accuracy: 0.82769 | train_auc: 0.93012 | valid_accuracy: 0.81589 | valid_auc: 0.87883 |  2:13:25s\n",
      "epoch 69 | loss: 0.35058 | train_accuracy: 0.82073 | train_auc: 0.92974 | valid_accuracy: 0.80976 | valid_auc: 0.87815 |  2:13:56s\n",
      "epoch 70 | loss: 0.35114 | train_accuracy: 0.80335 | train_auc: 0.92884 | valid_accuracy: 0.79146 | valid_auc: 0.87741 |  2:33:10s\n",
      "epoch 71 | loss: 0.35054 | train_accuracy: 0.81111 | train_auc: 0.93086 | valid_accuracy: 0.7998  | valid_auc: 0.87767 |  2:33:41s\n",
      "epoch 72 | loss: 0.35247 | train_accuracy: 0.8146  | train_auc: 0.93124 | valid_accuracy: 0.80349 | valid_auc: 0.8786  |  2:34:12s\n",
      "epoch 73 | loss: 0.34623 | train_accuracy: 0.80952 | train_auc: 0.93016 | valid_accuracy: 0.7974  | valid_auc: 0.87509 |  2:34:44s\n",
      "epoch 74 | loss: 0.34798 | train_accuracy: 0.81761 | train_auc: 0.9328  | valid_accuracy: 0.80644 | valid_auc: 0.87706 |  2:35:15s\n",
      "epoch 75 | loss: 0.34755 | train_accuracy: 0.81853 | train_auc: 0.93134 | valid_accuracy: 0.80559 | valid_auc: 0.87554 |  2:35:46s\n",
      "epoch 76 | loss: 0.34539 | train_accuracy: 0.81995 | train_auc: 0.93156 | valid_accuracy: 0.80559 | valid_auc: 0.87806 |  2:36:17s\n",
      "epoch 77 | loss: 0.34472 | train_accuracy: 0.81483 | train_auc: 0.9322  | valid_accuracy: 0.80098 | valid_auc: 0.87512 |  2:36:48s\n",
      "epoch 78 | loss: 0.34831 | train_accuracy: 0.81091 | train_auc: 0.9317  | valid_accuracy: 0.79895 | valid_auc: 0.87459 |  2:37:19s\n",
      "epoch 79 | loss: 0.34396 | train_accuracy: 0.82461 | train_auc: 0.93435 | valid_accuracy: 0.81331 | valid_auc: 0.87521 |  2:37:50s\n",
      "epoch 80 | loss: 0.34389 | train_accuracy: 0.82497 | train_auc: 0.93461 | valid_accuracy: 0.81198 | valid_auc: 0.87309 |  2:38:21s\n",
      "epoch 81 | loss: 0.34486 | train_accuracy: 0.83059 | train_auc: 0.93323 | valid_accuracy: 0.81703 | valid_auc: 0.8764  |  2:38:52s\n",
      "epoch 82 | loss: 0.34371 | train_accuracy: 0.8182  | train_auc: 0.93444 | valid_accuracy: 0.80548 | valid_auc: 0.87639 |  2:39:23s\n",
      "epoch 83 | loss: 0.34254 | train_accuracy: 0.81991 | train_auc: 0.93517 | valid_accuracy: 0.80751 | valid_auc: 0.87562 |  2:39:54s\n",
      "epoch 84 | loss: 0.34354 | train_accuracy: 0.81416 | train_auc: 0.93471 | valid_accuracy: 0.8012  | valid_auc: 0.87514 |  2:40:25s\n",
      "epoch 85 | loss: 0.34144 | train_accuracy: 0.82583 | train_auc: 0.93385 | valid_accuracy: 0.81124 | valid_auc: 0.87112 |  2:40:56s\n",
      "epoch 86 | loss: 0.34235 | train_accuracy: 0.80661 | train_auc: 0.9343  | valid_accuracy: 0.7929  | valid_auc: 0.8738  |  2:43:13s\n",
      "epoch 87 | loss: 0.34119 | train_accuracy: 0.82384 | train_auc: 0.93453 | valid_accuracy: 0.80995 | valid_auc: 0.87447 |  2:43:46s\n",
      "epoch 88 | loss: 0.34253 | train_accuracy: 0.82151 | train_auc: 0.93495 | valid_accuracy: 0.80681 | valid_auc: 0.87506 |  2:44:17s\n",
      "epoch 89 | loss: 0.33902 | train_accuracy: 0.83752 | train_auc: 0.93744 | valid_accuracy: 0.82394 | valid_auc: 0.87392 |  2:44:48s\n",
      "epoch 90 | loss: 0.33585 | train_accuracy: 0.82352 | train_auc: 0.93663 | valid_accuracy: 0.81032 | valid_auc: 0.87491 |  2:45:19s\n",
      "epoch 91 | loss: 0.3364  | train_accuracy: 0.82559 | train_auc: 0.93711 | valid_accuracy: 0.81176 | valid_auc: 0.8748  |  2:45:50s\n",
      "\n",
      "Early stopping occurred at epoch 91 with best_epoch = 41 and best_valid_auc = 0.88702\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "clf1_nopreproc = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type= 'entmax' #\"sparsemax\"\n",
    "                      )\n",
    "\n",
    "# fit the model \n",
    "clf1_nopreproc.fit(\n",
    "    train_features.values, train_labels, \\\n",
    "    eval_set=[(train_features.values, train_labels), (val_features.values, val_labels)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy','auc'],\n",
    "    max_epochs=1000 , patience=50,\n",
    "    batch_size=256, virtual_batch_size=64,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T21:22:02.565226Z",
     "iopub.status.busy": "2023-12-17T21:22:02.564484Z",
     "iopub.status.idle": "2023-12-17T21:48:57.653824Z",
     "shell.execute_reply": "2023-12-17T21:48:57.653318Z",
     "shell.execute_reply.started": "2023-12-17T21:22:02.565176Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 577.09662| val_0_unsup_loss_numpy: 12293.2880859375|  0:00:25s\n",
      "epoch 1  | loss: 211.11926| val_0_unsup_loss_numpy: 3038.433837890625|  0:00:51s\n",
      "epoch 2  | loss: 163.68941| val_0_unsup_loss_numpy: 2251.504638671875|  0:01:18s\n",
      "epoch 3  | loss: 158.3954| val_0_unsup_loss_numpy: 12903.640625|  0:01:44s\n",
      "epoch 4  | loss: 154.70088| val_0_unsup_loss_numpy: 31643.259765625|  0:02:10s\n",
      "epoch 5  | loss: 149.59659| val_0_unsup_loss_numpy: 4816.8857421875|  0:02:36s\n",
      "epoch 6  | loss: 146.00617| val_0_unsup_loss_numpy: 926.4320068359375|  0:03:02s\n",
      "epoch 7  | loss: 141.55473| val_0_unsup_loss_numpy: 1984.1365966796875|  0:03:28s\n",
      "epoch 8  | loss: 135.93664| val_0_unsup_loss_numpy: 790.2356567382812|  0:03:54s\n",
      "epoch 9  | loss: 130.86364| val_0_unsup_loss_numpy: 890.3836669921875|  0:04:20s\n",
      "epoch 10 | loss: 125.08631| val_0_unsup_loss_numpy: 535.3619995117188|  0:04:46s\n",
      "epoch 11 | loss: 121.87061| val_0_unsup_loss_numpy: 744.951171875|  0:05:12s\n",
      "epoch 12 | loss: 114.57169| val_0_unsup_loss_numpy: 3227.60791015625|  0:05:38s\n",
      "epoch 13 | loss: 110.66447| val_0_unsup_loss_numpy: 1699.0760498046875|  0:06:04s\n",
      "epoch 14 | loss: 103.85279| val_0_unsup_loss_numpy: 714.9273071289062|  0:06:31s\n",
      "epoch 15 | loss: 98.55279| val_0_unsup_loss_numpy: 7493.57080078125|  0:06:56s\n",
      "epoch 16 | loss: 96.17639| val_0_unsup_loss_numpy: 2751.015625|  0:07:22s\n",
      "epoch 17 | loss: 90.33245| val_0_unsup_loss_numpy: 792.5579833984375|  0:07:48s\n",
      "epoch 18 | loss: 104.05458| val_0_unsup_loss_numpy: 5300.4208984375|  0:08:14s\n",
      "epoch 19 | loss: 76.38181| val_0_unsup_loss_numpy: 2727.498779296875|  0:08:40s\n",
      "epoch 20 | loss: 73.13069| val_0_unsup_loss_numpy: 2410.334228515625|  0:09:06s\n",
      "epoch 21 | loss: 75.28762| val_0_unsup_loss_numpy: 2165.899658203125|  0:09:31s\n",
      "epoch 22 | loss: 68.62792| val_0_unsup_loss_numpy: 2914.472412109375|  0:09:57s\n",
      "epoch 23 | loss: 56.86076| val_0_unsup_loss_numpy: 3695.75048828125|  0:10:23s\n",
      "epoch 24 | loss: 54.61487| val_0_unsup_loss_numpy: 2988.523193359375|  0:10:49s\n",
      "epoch 25 | loss: 47.66562| val_0_unsup_loss_numpy: 2198.276611328125|  0:11:15s\n",
      "epoch 26 | loss: 62.54882| val_0_unsup_loss_numpy: 1330.037109375|  0:11:41s\n",
      "epoch 27 | loss: 91.02798| val_0_unsup_loss_numpy: 699.1046142578125|  0:12:07s\n",
      "epoch 28 | loss: 39.74345| val_0_unsup_loss_numpy: 1579.80517578125|  0:12:33s\n",
      "epoch 29 | loss: 54.53235| val_0_unsup_loss_numpy: 1625.986572265625|  0:12:59s\n",
      "epoch 30 | loss: 45.5832 | val_0_unsup_loss_numpy: 1078.44140625|  0:13:24s\n",
      "epoch 31 | loss: 89.30551| val_0_unsup_loss_numpy: 2194.435302734375|  0:13:50s\n",
      "epoch 32 | loss: 43.54456| val_0_unsup_loss_numpy: 4786.0966796875|  0:14:16s\n",
      "epoch 33 | loss: 96.5196 | val_0_unsup_loss_numpy: 5269.22021484375|  0:14:42s\n",
      "epoch 34 | loss: 41.34487| val_0_unsup_loss_numpy: 4986.90869140625|  0:15:08s\n",
      "epoch 35 | loss: 53.64464| val_0_unsup_loss_numpy: 2065.505615234375|  0:15:34s\n",
      "epoch 36 | loss: 59.27888| val_0_unsup_loss_numpy: 28750.81640625|  0:16:00s\n",
      "epoch 37 | loss: 52.85988| val_0_unsup_loss_numpy: 7247.03466796875|  0:16:52s\n",
      "epoch 38 | loss: 59.6658 | val_0_unsup_loss_numpy: 7663.82958984375|  0:17:17s\n",
      "epoch 39 | loss: 61.36987| val_0_unsup_loss_numpy: 34970.359375|  0:17:43s\n",
      "epoch 40 | loss: 51.68041| val_0_unsup_loss_numpy: 30419.841796875|  0:18:09s\n",
      "epoch 41 | loss: 59.59506| val_0_unsup_loss_numpy: 26585.6640625|  0:18:35s\n",
      "epoch 42 | loss: 48.46318| val_0_unsup_loss_numpy: 6868.8935546875|  0:19:00s\n",
      "epoch 43 | loss: 48.50776| val_0_unsup_loss_numpy: 2943.4736328125|  0:19:26s\n",
      "epoch 44 | loss: 91.56149| val_0_unsup_loss_numpy: 4025.172119140625|  0:19:52s\n",
      "epoch 45 | loss: 94.39313| val_0_unsup_loss_numpy: 3811.130126953125|  0:20:18s\n",
      "epoch 46 | loss: 37.16651| val_0_unsup_loss_numpy: 3686.520263671875|  0:20:44s\n",
      "epoch 47 | loss: 60.90798| val_0_unsup_loss_numpy: 2926.007568359375|  0:21:09s\n",
      "epoch 48 | loss: 56.23542| val_0_unsup_loss_numpy: 1936.825439453125|  0:21:35s\n",
      "epoch 49 | loss: 95.62485| val_0_unsup_loss_numpy: 4317.162109375|  0:22:01s\n",
      "epoch 50 | loss: 83.33223| val_0_unsup_loss_numpy: 4299.544921875|  0:22:27s\n",
      "epoch 51 | loss: 40.42544| val_0_unsup_loss_numpy: 3818.577392578125|  0:22:53s\n",
      "epoch 52 | loss: 28.40568| val_0_unsup_loss_numpy: 15181.9560546875|  0:23:19s\n",
      "epoch 53 | loss: 47.11894| val_0_unsup_loss_numpy: 3103.675537109375|  0:23:45s\n",
      "epoch 54 | loss: 66.28669| val_0_unsup_loss_numpy: 3950.3974609375|  0:24:11s\n",
      "epoch 55 | loss: 30.7007 | val_0_unsup_loss_numpy: 6859.66455078125|  0:24:36s\n",
      "epoch 56 | loss: 106.8298| val_0_unsup_loss_numpy: 20927.76171875|  0:25:02s\n",
      "epoch 57 | loss: 90.76408| val_0_unsup_loss_numpy: 14729.310546875|  0:25:28s\n",
      "epoch 58 | loss: 55.36224| val_0_unsup_loss_numpy: 12398.900390625|  0:25:54s\n",
      "epoch 59 | loss: 27.54522| val_0_unsup_loss_numpy: 12658.8544921875|  0:26:20s\n",
      "epoch 60 | loss: 30.52169| val_0_unsup_loss_numpy: 11567.330078125|  0:26:46s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 10 and best_val_0_unsup_loss_numpy = 535.3619995117188\n",
      "Successfully saved model at ./test_pretrain3.zip\n"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model_no_preproc = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    )\n",
    "\n",
    "# fit the model\n",
    "unsupervised_model_no_preproc.fit(\n",
    "    train_features.values,\n",
    "    eval_set=[val_features.values],\n",
    "    max_epochs=1000 , patience=50,\n",
    "    batch_size=256, virtual_batch_size=64,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.8,\n",
    "\n",
    ")\n",
    "# Make reconstruction from a dataset\n",
    "reconstructed_X, embedded_X = unsupervised_model_no_preproc.predict(train_features.values,)\n",
    "assert(reconstructed_X.shape==embedded_X.shape)\n",
    "\n",
    "unsupervised_model_no_preproc.save_model('./test_pretrain3')\n",
    "loaded_pretrain2 = TabNetPretrainer()\n",
    "loaded_pretrain2.load_model('./test_pretrain3.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T00:01:06.637531Z",
     "iopub.status.busy": "2023-12-18T00:01:06.636886Z",
     "iopub.status.idle": "2023-12-18T00:43:44.655208Z",
     "shell.execute_reply": "2023-12-18T00:43:44.654617Z",
     "shell.execute_reply.started": "2023-12-18T00:01:06.637467Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.68342 | train_accuracy: 0.78769 | train_auc: 0.72509 | valid_accuracy: 0.7915  | valid_auc: 0.72798 |  0:00:31s\n",
      "epoch 1  | loss: 0.58104 | train_accuracy: 0.7695  | train_auc: 0.80835 | valid_accuracy: 0.76747 | valid_auc: 0.81478 |  0:01:01s\n",
      "epoch 2  | loss: 0.53523 | train_accuracy: 0.80262 | train_auc: 0.83487 | valid_accuracy: 0.80139 | valid_auc: 0.84122 |  0:01:32s\n",
      "epoch 3  | loss: 0.51123 | train_accuracy: 0.80904 | train_auc: 0.84577 | valid_accuracy: 0.8094  | valid_auc: 0.8528  |  0:02:03s\n",
      "epoch 4  | loss: 0.49171 | train_accuracy: 0.81206 | train_auc: 0.85607 | valid_accuracy: 0.81405 | valid_auc: 0.86076 |  0:02:33s\n",
      "epoch 5  | loss: 0.48075 | train_accuracy: 0.80756 | train_auc: 0.86093 | valid_accuracy: 0.81017 | valid_auc: 0.86484 |  0:03:04s\n",
      "epoch 6  | loss: 0.47243 | train_accuracy: 0.81254 | train_auc: 0.86439 | valid_accuracy: 0.81202 | valid_auc: 0.86894 |  0:03:35s\n",
      "epoch 7  | loss: 0.46473 | train_accuracy: 0.81199 | train_auc: 0.87048 | valid_accuracy: 0.81165 | valid_auc: 0.87384 |  0:04:06s\n",
      "epoch 8  | loss: 0.45347 | train_accuracy: 0.81959 | train_auc: 0.87514 | valid_accuracy: 0.81881 | valid_auc: 0.87601 |  0:04:36s\n",
      "epoch 9  | loss: 0.45151 | train_accuracy: 0.81198 | train_auc: 0.8775  | valid_accuracy: 0.81179 | valid_auc: 0.87673 |  0:05:55s\n",
      "epoch 10 | loss: 0.44897 | train_accuracy: 0.81439 | train_auc: 0.88029 | valid_accuracy: 0.81224 | valid_auc: 0.87805 |  0:06:26s\n",
      "epoch 11 | loss: 0.44017 | train_accuracy: 0.81212 | train_auc: 0.88402 | valid_accuracy: 0.80855 | valid_auc: 0.88103 |  0:06:57s\n",
      "epoch 12 | loss: 0.43705 | train_accuracy: 0.81069 | train_auc: 0.88519 | valid_accuracy: 0.80737 | valid_auc: 0.88059 |  0:07:28s\n",
      "epoch 13 | loss: 0.4342  | train_accuracy: 0.82099 | train_auc: 0.88692 | valid_accuracy: 0.81903 | valid_auc: 0.88262 |  0:07:58s\n",
      "epoch 14 | loss: 0.43021 | train_accuracy: 0.81941 | train_auc: 0.88933 | valid_accuracy: 0.81412 | valid_auc: 0.88216 |  0:08:29s\n",
      "epoch 15 | loss: 0.42843 | train_accuracy: 0.82033 | train_auc: 0.89114 | valid_accuracy: 0.81689 | valid_auc: 0.88301 |  0:09:00s\n",
      "epoch 16 | loss: 0.42448 | train_accuracy: 0.82543 | train_auc: 0.89319 | valid_accuracy: 0.82198 | valid_auc: 0.88255 |  0:09:31s\n",
      "epoch 17 | loss: 0.42105 | train_accuracy: 0.83285 | train_auc: 0.89632 | valid_accuracy: 0.82862 | valid_auc: 0.88465 |  0:10:01s\n",
      "epoch 18 | loss: 0.41676 | train_accuracy: 0.81875 | train_auc: 0.89781 | valid_accuracy: 0.81508 | valid_auc: 0.88446 |  0:10:32s\n",
      "epoch 19 | loss: 0.41273 | train_accuracy: 0.8235  | train_auc: 0.89917 | valid_accuracy: 0.81836 | valid_auc: 0.88383 |  0:11:03s\n",
      "epoch 20 | loss: 0.4084  | train_accuracy: 0.82557 | train_auc: 0.89938 | valid_accuracy: 0.82146 | valid_auc: 0.88374 |  0:11:34s\n",
      "epoch 21 | loss: 0.40772 | train_accuracy: 0.82572 | train_auc: 0.90149 | valid_accuracy: 0.82061 | valid_auc: 0.8829  |  0:12:04s\n",
      "epoch 22 | loss: 0.40404 | train_accuracy: 0.82437 | train_auc: 0.90438 | valid_accuracy: 0.81877 | valid_auc: 0.88305 |  0:12:35s\n",
      "epoch 23 | loss: 0.39817 | train_accuracy: 0.81747 | train_auc: 0.90533 | valid_accuracy: 0.81172 | valid_auc: 0.88176 |  0:13:06s\n",
      "epoch 24 | loss: 0.39852 | train_accuracy: 0.82664 | train_auc: 0.90597 | valid_accuracy: 0.82069 | valid_auc: 0.87971 |  0:13:36s\n",
      "epoch 25 | loss: 0.39685 | train_accuracy: 0.81621 | train_auc: 0.9062  | valid_accuracy: 0.80991 | valid_auc: 0.882   |  0:14:07s\n",
      "epoch 26 | loss: 0.39094 | train_accuracy: 0.8288  | train_auc: 0.90914 | valid_accuracy: 0.82268 | valid_auc: 0.88303 |  0:14:38s\n",
      "epoch 27 | loss: 0.39259 | train_accuracy: 0.83959 | train_auc: 0.90777 | valid_accuracy: 0.83335 | valid_auc: 0.88143 |  0:15:09s\n",
      "epoch 28 | loss: 0.39196 | train_accuracy: 0.84182 | train_auc: 0.91127 | valid_accuracy: 0.83349 | valid_auc: 0.88205 |  0:15:40s\n",
      "epoch 29 | loss: 0.38707 | train_accuracy: 0.82077 | train_auc: 0.91342 | valid_accuracy: 0.81357 | valid_auc: 0.88258 |  0:16:11s\n",
      "epoch 30 | loss: 0.3827  | train_accuracy: 0.8342  | train_auc: 0.91586 | valid_accuracy: 0.82641 | valid_auc: 0.88319 |  0:16:41s\n",
      "epoch 31 | loss: 0.38264 | train_accuracy: 0.83326 | train_auc: 0.91568 | valid_accuracy: 0.82504 | valid_auc: 0.88244 |  0:17:12s\n",
      "epoch 32 | loss: 0.38191 | train_accuracy: 0.82597 | train_auc: 0.91502 | valid_accuracy: 0.81881 | valid_auc: 0.88136 |  0:17:43s\n",
      "epoch 33 | loss: 0.37552 | train_accuracy: 0.8331  | train_auc: 0.91872 | valid_accuracy: 0.82368 | valid_auc: 0.87937 |  0:18:14s\n",
      "epoch 34 | loss: 0.37412 | train_accuracy: 0.83664 | train_auc: 0.91857 | valid_accuracy: 0.82704 | valid_auc: 0.88069 |  0:18:45s\n",
      "epoch 35 | loss: 0.37399 | train_accuracy: 0.81953 | train_auc: 0.91947 | valid_accuracy: 0.81006 | valid_auc: 0.87894 |  0:19:16s\n",
      "epoch 36 | loss: 0.37553 | train_accuracy: 0.82564 | train_auc: 0.91726 | valid_accuracy: 0.8136  | valid_auc: 0.87499 |  0:19:47s\n",
      "epoch 37 | loss: 0.37096 | train_accuracy: 0.82791 | train_auc: 0.91994 | valid_accuracy: 0.81836 | valid_auc: 0.88096 |  0:20:17s\n",
      "epoch 38 | loss: 0.37159 | train_accuracy: 0.83751 | train_auc: 0.92077 | valid_accuracy: 0.82578 | valid_auc: 0.87851 |  0:20:48s\n",
      "epoch 39 | loss: 0.36605 | train_accuracy: 0.83289 | train_auc: 0.9241  | valid_accuracy: 0.82227 | valid_auc: 0.87718 |  0:21:19s\n",
      "epoch 40 | loss: 0.36566 | train_accuracy: 0.82362 | train_auc: 0.92386 | valid_accuracy: 0.81235 | valid_auc: 0.87664 |  0:21:50s\n",
      "epoch 41 | loss: 0.36746 | train_accuracy: 0.84271 | train_auc: 0.92404 | valid_accuracy: 0.83098 | valid_auc: 0.87759 |  0:22:20s\n",
      "epoch 42 | loss: 0.36335 | train_accuracy: 0.82277 | train_auc: 0.92503 | valid_accuracy: 0.81283 | valid_auc: 0.87634 |  0:22:51s\n",
      "epoch 43 | loss: 0.36298 | train_accuracy: 0.82118 | train_auc: 0.92562 | valid_accuracy: 0.81017 | valid_auc: 0.87638 |  0:23:22s\n",
      "epoch 44 | loss: 0.36166 | train_accuracy: 0.82804 | train_auc: 0.92708 | valid_accuracy: 0.81622 | valid_auc: 0.87712 |  0:23:53s\n",
      "epoch 45 | loss: 0.3564  | train_accuracy: 0.8407  | train_auc: 0.92674 | valid_accuracy: 0.8305  | valid_auc: 0.87808 |  0:24:24s\n",
      "epoch 46 | loss: 0.35926 | train_accuracy: 0.83449 | train_auc: 0.92829 | valid_accuracy: 0.82087 | valid_auc: 0.87659 |  0:24:54s\n",
      "epoch 47 | loss: 0.35499 | train_accuracy: 0.82721 | train_auc: 0.92544 | valid_accuracy: 0.81604 | valid_auc: 0.87572 |  0:25:25s\n",
      "epoch 48 | loss: 0.35618 | train_accuracy: 0.83116 | train_auc: 0.92832 | valid_accuracy: 0.81929 | valid_auc: 0.87556 |  0:25:56s\n",
      "epoch 49 | loss: 0.355   | train_accuracy: 0.82886 | train_auc: 0.92993 | valid_accuracy: 0.81637 | valid_auc: 0.87509 |  0:28:04s\n",
      "epoch 50 | loss: 0.3504  | train_accuracy: 0.83164 | train_auc: 0.9299  | valid_accuracy: 0.81954 | valid_auc: 0.87632 |  0:28:35s\n",
      "epoch 51 | loss: 0.35154 | train_accuracy: 0.83113 | train_auc: 0.92969 | valid_accuracy: 0.81703 | valid_auc: 0.87457 |  0:29:06s\n",
      "epoch 52 | loss: 0.35109 | train_accuracy: 0.82733 | train_auc: 0.92938 | valid_accuracy: 0.81294 | valid_auc: 0.87367 |  0:29:36s\n",
      "epoch 53 | loss: 0.34922 | train_accuracy: 0.83148 | train_auc: 0.93054 | valid_accuracy: 0.81836 | valid_auc: 0.87461 |  0:30:07s\n",
      "epoch 54 | loss: 0.34683 | train_accuracy: 0.83456 | train_auc: 0.93112 | valid_accuracy: 0.8232  | valid_auc: 0.87621 |  0:30:38s\n",
      "epoch 55 | loss: 0.34677 | train_accuracy: 0.83829 | train_auc: 0.93207 | valid_accuracy: 0.82283 | valid_auc: 0.87192 |  0:31:08s\n",
      "epoch 56 | loss: 0.34628 | train_accuracy: 0.84124 | train_auc: 0.93197 | valid_accuracy: 0.82921 | valid_auc: 0.87499 |  0:31:39s\n",
      "epoch 57 | loss: 0.3465  | train_accuracy: 0.83044 | train_auc: 0.93211 | valid_accuracy: 0.81689 | valid_auc: 0.8754  |  0:32:10s\n",
      "epoch 58 | loss: 0.34687 | train_accuracy: 0.83104 | train_auc: 0.93344 | valid_accuracy: 0.81593 | valid_auc: 0.87499 |  0:32:40s\n",
      "epoch 59 | loss: 0.34542 | train_accuracy: 0.83577 | train_auc: 0.9343  | valid_accuracy: 0.8236  | valid_auc: 0.87408 |  0:33:11s\n",
      "epoch 60 | loss: 0.34334 | train_accuracy: 0.83035 | train_auc: 0.93442 | valid_accuracy: 0.81641 | valid_auc: 0.87346 |  0:38:01s\n",
      "epoch 61 | loss: 0.33984 | train_accuracy: 0.83604 | train_auc: 0.93554 | valid_accuracy: 0.81988 | valid_auc: 0.87221 |  0:38:32s\n",
      "epoch 62 | loss: 0.33849 | train_accuracy: 0.82843 | train_auc: 0.93476 | valid_accuracy: 0.81416 | valid_auc: 0.87242 |  0:39:03s\n",
      "epoch 63 | loss: 0.33791 | train_accuracy: 0.84344 | train_auc: 0.93482 | valid_accuracy: 0.82988 | valid_auc: 0.87251 |  0:39:34s\n",
      "epoch 64 | loss: 0.33862 | train_accuracy: 0.83063 | train_auc: 0.93476 | valid_accuracy: 0.81644 | valid_auc: 0.8697  |  0:40:05s\n",
      "epoch 65 | loss: 0.33722 | train_accuracy: 0.82905 | train_auc: 0.93725 | valid_accuracy: 0.81441 | valid_auc: 0.87223 |  0:40:36s\n",
      "epoch 66 | loss: 0.33811 | train_accuracy: 0.82957 | train_auc: 0.93696 | valid_accuracy: 0.81353 | valid_auc: 0.8713  |  0:41:07s\n",
      "epoch 67 | loss: 0.33843 | train_accuracy: 0.83506 | train_auc: 0.93664 | valid_accuracy: 0.8208  | valid_auc: 0.87241 |  0:41:37s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 17 and best_valid_auc = 0.88465\n"
     ]
    }
   ],
   "source": [
    "clf2_preproc = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax' # This will be overwritten if using pretrain model\n",
    "                      )\n",
    "clf2_preproc.fit(\n",
    "    train_features.values, train_labels, \\\n",
    "    eval_set=[(train_features.values, train_labels), (val_features.values, val_labels)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy','auc'],\n",
    "    max_epochs=1000 , patience=50,\n",
    "    batch_size=256, virtual_batch_size=64,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=loaded_pretrain2\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_to_dataset_testing(dataframe, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  df = {key: np.array(value)[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df)))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130003,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = df_to_dataset_testing(test_data, shuffle = False, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = prediction\n",
    "sample_submission[\"target\"] = pd.DataFrame.fillna(sample_submission[\"target\"], value = 0)\n",
    "sample_submission.to_csv(f'{OUTPUT_DIR}/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf1_nonproc.predict()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mmai863",
   "language": "python",
   "name": "mmai863"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
